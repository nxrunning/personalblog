<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Nien Xiang Tou</title>
<link>https://nienxiangtou.com/index.html</link>
<atom:link href="https://nienxiangtou.com/index.xml" rel="self" type="application/rss+xml"/>
<description>Personal blog that documents my personal projects</description>
<image>
<url>https://nienxiangtou.com/Profilephoto.jfif</url>
<title>Nien Xiang Tou</title>
<link>https://nienxiangtou.com/index.html</link>
</image>
<generator>quarto-1.0.36</generator>
<lastBuildDate>Thu, 14 Apr 2022 16:00:00 GMT</lastBuildDate>
<item>
  <title>Bayesian versus Frequentist solutions to the Monty Hall Problem</title>
  <dc:creator>Nien Xiang Tou</dc:creator>
  <link>https://nienxiangtou.com/posts/Bayesian-vs-Frequentist-Monty-Hall/index.html</link>
  <description><![CDATA[ 



<p>There are generally two schools of thoughts in defining probability: Bayesian and Frequentism. The former views probability as a degree of our beliefs towards an event occurrence, while the latter views it as a relative frequency of an event occurrence. This post presents the use of both Bayesian and frequentist approaches to solve the famous Monty Hall problem.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/Bayesian-vs-Frequentist-Monty-Hall/image.webp" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Illustration of the Monty Hall problem. Source: Author</figcaption><p></p>
</figure>
</div>
<section id="monty-hall-problem" class="level2">
<h2 class="anchored" data-anchor-id="monty-hall-problem">Monty Hall Problem</h2>
<p>I first chanced upon this probability puzzle in the movie, <em>21</em>. This puzzle originated from an old American game show <em>Let’s Make a Deal</em>, and was named after the host <em>Monty Hall</em>. Based on <a href="https://en.wikipedia.org/wiki/Monty_Hall_problem"><u>Wikipedia</u></a>, this was made famous in a letter to <em>Marilyn vos Savant</em>’s “Ask Marilyn” column in 1990:</p>
<blockquote class="blockquote">
<p><span style="font-size: 20px">Suppose you’re on a game show, and you’re given the choice of three doors: Behind one door is a car; behind the others, goats. You pick a door, say No.&nbsp;1, and the host, who knows what’s behind the doors, opens another door, say No.&nbsp;3, which has a goat. He then says to you, “Do you want to pick door No.&nbsp;2?” Is it to your advantage to switch your choice?</span></p>
</blockquote>
<p>Marilyn proposed that you should always switch, as it would double your chance of winning the car from 1/3 to 2/3. This answer was met with huge criticism as people intuitively tend to think that since there are only two doors left, the probability of the car behind either door is 1/2. Hence, the odds are the same regardless of your choice to switch the door. In this blog post, I would demonstrate how we can use either the Bayesian or frequentist approach to answer this paradox.</p>
</section>
<section id="thinking-like-a-bayesian" class="level2">
<h2 class="anchored" data-anchor-id="thinking-like-a-bayesian">Thinking like a Bayesian</h2>
<p>The Bayesian school of thought takes a subjective approach towards probability, and is based on the Bayes’ Theorem. It is fundamentally a concept of conditional probability defined by the formula below. In a nutshell, the resulting probability also known as the posterior probability is derived using three components: the likelihood, the prior probability, and the probability of observing the evidence (to normalize the numerator to a value between 0 and 1). I have written how we can use the Bayes’ Theorem to explain why different individuals appraise similar empirical evidence differently in my <a href="https://www.nienxiangtou.com/posts/all-about-that-bayes/">previous blog post</a>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/Bayesian-vs-Frequentist-Monty-Hall/image2.webp" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Bayes’ Theorem</figcaption><p></p>
</figure>
</div>
<p>In the context of the Monty Hall problem, we are interested in comparing the probability between switching or sticking to our initial choice of door given that the host chose to open a door with a goat behind. Using the example problem presented above, given that door 3 has been revealed to be a goat, the car would be either behind door 1 (our initial choice) or door 2 (if we choose to switch). To solve the problem, let us apply the Bayes’ Theorem formula and compare P (door 1 = car | opens = door 3) and P (door 2 = car | opens = door 3).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/Bayesian-vs-Frequentist-Monty-Hall/image3.webp" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Application of Bayes’ Theorem to the Monty Hall problem</figcaption><p></p>
</figure>
</div>
<section id="prior-probability---pa" class="level3">
<h3 class="anchored" data-anchor-id="prior-probability---pa">Prior Probability - P(A)</h3>
<p>Let’s start with the simplest probability to compute, the prior probability. This refers to our initial expected probability of the car behind either door 1 and door 2 at the start of the game before door 3 was opened. Assuming that the car was randomly assigned, each door has an equal chance of having the car behind. Thus, P (door 1 = car) and P (door 2 = car) have equal probability of 1/3.</p>
</section>
<section id="likelihood---pba" class="level3">
<h3 class="anchored" data-anchor-id="likelihood---pba">Likelihood - P(B|A)</h3>
<p>Next, we would compute the likelihood of the host opening door 3 for respective hypotheses. For the first hypothesis, if the car is behind door 1, the host can either open door 2 or 3 to reveal a goat. Hence, P (opens = door 3 | door 1 = car) is 1/2. On the other hand, if the car is behind door 2, the host has no other choice but to open door 3 since it is the only other door with the goat behind. Therefore, for the second hypothesis, P (opens = door 3 | door 2 = car) equals 1.</p>
</section>
<section id="joint-probability---pba-x-pa" class="level3">
<h3 class="anchored" data-anchor-id="joint-probability---pba-x-pa">Joint Probability - P(B|A) X P(A)</h3>
<p>With the likelihood and prior probability values known, we can work out the numerator values of the formula for both hypotheses.</p>
<p>P (opens = door 3 | door 1 = car) X P (door 1 = car) = 1/2 X 1/3 = 1/6</p>
<p>P (opens = door 3 | door 2 = car) X P (door 1 = car) = 1 X 1/3 = 1/3</p>
</section>
<section id="probability-of-observed-evidence---pb" class="level3">
<h3 class="anchored" data-anchor-id="probability-of-observed-evidence---pb">Probability of observed evidence - P(B)</h3>
<p>We can derive the probability of observed evidence by simply adding up the joint probabilities. This value represents the probability that the host chose to open door 3 given the contestant’s selection of door 1.</p>
<p>P (opens = door 3) = 1/6 + 1/3 = 1/2</p>
</section>
<section id="posterior-probability---pab" class="level3">
<h3 class="anchored" data-anchor-id="posterior-probability---pab">Posterior Probability - P(A|B)</h3>
<p>Finally, we can solve for our posterior probabilities by inputting all the derived values above into the formula.</p>
<p>P (door 1 = car | opens = door 3) = (1/6) / (1/2) = 1/3</p>
<p>P (door 2 = car | opens = door 3) = (1/3) / (1/2) = 2/3</p>
<p>The posterior probability values show us that if we stick to our choice of door 1 after the host revealed a goat behind door 3, the chances of winning a car is 1/3. On the contrary, if we choose to take up the offer to switch to door 2, our chances are doubled to 2/3. Therefore, the Bayesian approach supports Marilyn vos Savant’s suggestion to always make the switch if given the choice to.</p>
</section>
</section>
<section id="thinking-like-a-frequentist" class="level2">
<h2 class="anchored" data-anchor-id="thinking-like-a-frequentist">Thinking like a Frequentist</h2>
<p>In contrast to a Bayesian approach, as the name suggests, a frequentist determines probability based on sampling frequency instead. For example, if we want to know the probability of getting a ‘heads’ in a coin flip, we may flip the coin for x number of trials and determine the probability based on the frequency distribution of a ‘heads’ occurrence. As purported by Bernoulli’s Law of Large Numbers, the long-run frequency of an event occurrence would converge to its theoretical probability. Therefore, in order to solve the Monty Hall problem, we may run a simulation of the game show puzzle over a large number of trials and compare the frequency of winning a car between the decision to stick to our initial choice and the decision to switch our choices.</p>
<p>For this project, I performed a Monte Carlo simulation using python programming language. The Monty Hall game was simulated for a reasonably large number of repetitions and the odds of winning was recorded for respective strategies. The only required package for the simulation is the <em>random</em> package. First, I created three empty lists to store the results for each sample simulation.</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;"># Create empty lists to store simulation results output</span></span>
<span id="cb1-2">chance_of_winning_ifswitch_list <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb1-3">chance_of_winning_ifdonotswitch_list <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb1-4">percentage_diff_list <span class="op" style="color: #5E5E5E;">=</span> []</span></code></pre></div>
<p>Next, the simulation was set up using ‘for-loops’. In each simulation loop, the locations of the car and goats were randomly assigned and a random door was chosen as the contestant’s initial selection. Given that the game host would always open another door with a goat, the decision to switch would backfire only if the initial selected door happens to have the car prize behind. In other words, the probability of winning if choose not to switch choices is equivalent to the probability of choosing the door with the car in the first place. Therefore, an ‘if-else’ conditional statement was included to check whether the initially selected door has a car or not. If the chosen door does not have a car behind, we assign a value of 1 to represent the event of winning when choose to switch choices. If the chosen door has a car behind, we assign a value of 0 to represent the event of winning when choose not to switch choices.</p>
<p>To determine the frequency of winning for each strategy, the odds of winning were calculated based on a sample of 1,000 simulated rounds of the Monty Hall game. This sampling was repeated 10,000 times to determine the distribution of winning percentages for each strategy. A random seed value was set for reproducibility of the results.</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;"># Create simulation using for-loops</span></span>
<span id="cb2-2"><span class="co" style="color: #5E5E5E;"># Repeat 10000 trials with 1000 samples per trial</span></span>
<span id="cb2-3"></span>
<span id="cb2-4"><span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(<span class="dv" style="color: #AD0000;">10000</span>):    </span>
<span id="cb2-5">    results_list <span class="op" style="color: #5E5E5E;">=</span> []    </span>
<span id="cb2-6"></span>
<span id="cb2-7">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(<span class="dv" style="color: #AD0000;">1000</span>):        </span>
<span id="cb2-8">        door_list <span class="op" style="color: #5E5E5E;">=</span> [<span class="st" style="color: #20794D;">"car"</span>, <span class="st" style="color: #20794D;">"goat"</span>, <span class="st" style="color: #20794D;">"goat"</span>]                 </span>
<span id="cb2-9">        random.shuffle(door_list)        </span>
<span id="cb2-10">        chosen_door_number <span class="op" style="color: #5E5E5E;">=</span> random.sample(<span class="bu" style="color: null;">range</span>(<span class="dv" style="color: #AD0000;">3</span>), <span class="dv" style="color: #AD0000;">1</span>)        </span>
<span id="cb2-11">        chosen_door <span class="op" style="color: #5E5E5E;">=</span> door_list[chosen_door_number[<span class="dv" style="color: #AD0000;">0</span>]]        </span>
<span id="cb2-12">        </span>
<span id="cb2-13">        <span class="cf" style="color: #003B4F;">if</span> chosen_door <span class="op" style="color: #5E5E5E;">!=</span> <span class="st" style="color: #20794D;">"car"</span>:            </span>
<span id="cb2-14">            results_list.append(<span class="dv" style="color: #AD0000;">1</span>)        </span>
<span id="cb2-15">        <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb2-16">            results_list.append(<span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb2-17">    </span>
<span id="cb2-18">    <span class="co" style="color: #5E5E5E;"># Compute winning percentage if choose to switch  </span></span>
<span id="cb2-19">    chance_of_winning_ifswitch <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">sum</span>(results_list)<span class="op" style="color: #5E5E5E;">/</span><span class="bu" style="color: null;">len</span>(results_list)<span class="op" style="color: #5E5E5E;">*</span><span class="dv" style="color: #AD0000;">100</span>              </span>
<span id="cb2-20">    </span>
<span id="cb2-21">    <span class="co" style="color: #5E5E5E;"># Compute winning percentage if choose not to switch</span></span>
<span id="cb2-22">    chance_of_winning_ifdonotswitch <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">100</span> <span class="op" style="color: #5E5E5E;">-</span> chance_of_winning_ifswitch                    </span>
<span id="cb2-23">    </span>
<span id="cb2-24">    <span class="co" style="color: #5E5E5E;"># Compute difference in winning percentage between the two strategies             </span></span>
<span id="cb2-25">    percentage_diff <span class="op" style="color: #5E5E5E;">=</span> chance_of_winning_ifswitch <span class="op" style="color: #5E5E5E;">-</span> chance_of_winning_ifdonotswitch  </span>
<span id="cb2-26">             </span>
<span id="cb2-27">    <span class="co" style="color: #5E5E5E;"># Append the results to respective lists                </span></span>
<span id="cb2-28">    chance_of_winning_ifswitch_list.append(chance_of_winning_ifswitch)                             </span>
<span id="cb2-29">    chance_of_winning_ifdonotswitch_list.append(chance_of_winning_ifdonotswitch)    </span>
<span id="cb2-30">    percentage_diff_list.append(percentage_diff)</span></code></pre></div>
<p>The figure below illustrates the distribution of winning odds for both strategies based on our simulation results. The blue histogram presents the distribution for the strategy to switch while the yellow histogram presents the distribution for the strategy to stick to the initial choice. In accordance with the central limit theorem, the distribution of sample means would approximate a Gaussian or normal distribution when the sample size is large. As expected from our large number of simulation trials, we observe a bell curve that characterises a normal distribution.</p>
<p><img src="https://nienxiangtou.com/posts/Bayesian-vs-Frequentist-Monty-Hall/image4.webp" class="img-fluid"></p>
<p>The x-axes of the two histograms clearly indicate the difference in odds of winning between the two strategies. You go home with a car 62-72% of the time if you choose to switch as opposed to 28-38% if you choose not to switch. This is further supported by the 95% confidence intervals computed for both strategies. Within 95% of the sampled winning odds from the 10,000 trials, the frequency of winning if you switch is between 66.646 and 66.705% while sticking to the same door selection would be between 33.295 and 33.354% instead. Since the 95% confidence intervals do not overlap, we can infer that there is a statistically significant difference in winning percentage between the two strategies. Indeed, as illustrated in the third histogram (orange in colour), we are 95% confident that choosing to switch would increase our odds of winning by 33.293 to 33.410%. Therefore, the frequentist approach also supports <em>Marilyn vos Savant</em>’s suggestion to always make the switch if given the choice to.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>This blog post has demonstrated the use of Bayesian and Frequentist approaches to solve the Monty Hall problem. Through the examples above, we can see the different approaches to derive probability values. While both approaches are different, the probabilities derived were similar to one another in the context of the Monty Hall problem. The results clearly suggest that regardless whether you subscribe to a Bayesian or Frequentist paradigm, switching your choice is always a wiser option to increase the chances of winning the car.</p>
<p>Simulation, analysis and visualisation were performed using Python. Full code can be found <a href="https://github.com/nxrunning/Personal-Projects/blob/Monty-Hall-Problem-Simulation/Code">here</a>.</p>


</section>

 ]]></description>
  <category>Statistics</category>
  <guid>https://nienxiangtou.com/posts/Bayesian-vs-Frequentist-Monty-Hall/index.html</guid>
  <pubDate>Thu, 14 Apr 2022 16:00:00 GMT</pubDate>
  <media:content url="https://nienxiangtou.com/posts/Bayesian-vs-Frequentist-Monty-Hall/image.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>Tokyo Olympics: Analysis of the 1500m Event’s Pacing Strategy using the Concept of Critical Speed</title>
  <dc:creator>Nien Xiang Tou</dc:creator>
  <link>https://nienxiangtou.com/posts/Tokyo-olympics-1500m-analysis/index.html</link>
  <description><![CDATA[ 



<p>The 1500m event is a demanding middle-distance race in which athletes have to sustain high-intensity efforts over prolonged periods. This blog post employs the concept of critical speed to analyse the pacing strategy in the men’s and women’s 1500m finals at the Tokyo Olympics 2020.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/Tokyo-olympics-1500m-analysis/image.webp" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">The Men’s 1500m Finals at the Tokyo Olympics. Source: Reuters/Andrew Boyers</figcaption><p></p>
</figure>
</div>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Energy output during prolonged cardiorespiratory exercise is produced from a spectrum of both the aerobic (oxidative) and anaerobic (glycolytic) energy systems. The proportion of contribution from either system is often dependent on the exercise intensity levels. Given that venturing into the anaerobic territories is typically associated with fatigue, it has been of interest to scientists, coaches, and athletes to find the optimal exercise intensity to meet the demands of sporting performances.</p>
<p>Numerous concepts have been established in sports science to try identifying key levels of exercise intensity to predict fatigue and performance. One such concept often used in the world of cycling is the concept of <em>critical power</em>. In layman terms, critical power represents the highest power output that can be sustained for a prolonged period (approximately 30-60 minutes). It has been purported to be a key ‘threshold’ that distinguishes between the heavy and severe intensity domains. The latter domain is characterised by rapid increase in oxygen uptake and blood lactate, and the inability to reach steady states. Any intensity beyond the critical power level will result in the athlete tapping significantly into his or her finite anaerobic capacity. Continuous exercise at such high intensity levels will result in inevitably imminent fatigue.</p>
<p>The concept of critical power is relevant to any sporting performances in which athletes have to exercise in the severe intensity domain. A good applicable example in the athletics will be the 1500m event, which requires significant energy contribution from the anaerobic system. In the context of running, the same concept is termed <em>critical speed</em> instead since running is more pertinent to speed than power output. An interesting application of this concept is predicting the time to exhaustion when running beyond the critical speed using the following equation.</p>
<p><span data-text-align="center"><strong>Time to exhaustion = D’/ (S – CS)</strong></span></p>
<p>The concept proposes that when one runs at a given speed (S) above the critical speed (CS), the ability to sustain that speed is limited by the individual’s work capacity (D’). For example, a runner has a CS of 5 m/s and D’ of 200m. If this runner attempts to run at a speed of 7 m/s, it is expected that he or she will reach exhaustion in 100 seconds (as calculated by 200/ (7-5) = 100).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/Tokyo-olympics-1500m-analysis/image2.webp" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Illustration of the critical speed concept</figcaption><p></p>
</figure>
</div>
</section>
<section id="calculation-of-critical-speed-cs-and-work-capacity-d" class="level2">
<h2 class="anchored" data-anchor-id="calculation-of-critical-speed-cs-and-work-capacity-d">Calculation of Critical Speed (CS) and Work Capacity (D’)</h2>
<p>Critical speed (CS) can be computed using the personal records of an individual over different running distances. As illustrated in the figure above, we plot the average speed of one’s best performances against their respective time duration. We will derive a hyperbolic relationship between speed and time. On the left side of the curve, we observe an initial steep decline in the speed that we can sustain as the time duration increases. However, the rate of decline slows and beyond a certain point, any increase in time duration corresponds to minimal changes in the speed. The curve eventually approximates the dotted line, termed the asymptote, which represents the CS. In addition, we can also derive one’s work capacity (D’) from the curve, as denoted by the shaded areas.</p>
<p>Given that it requires some effort to interpret a hyperbolic curve, an easier and commonly used method to calculate CS and D’ is to plot the total work done (distance of event) against the time duration, which has a linear relationship. Next, we fit a linear regression line to the values and interpret the values from the straight-line equation. The slope or gradient of the line represents CS, while the y-intercept represents D’. The figure below illustrates an example of this method to calculate the CS and D’ of Timothy Cheruiyot, who is currently first ranking in the men’s 1500m event. I plotted his personal best records between 800-5000m (data from IAAF database) and derived the linear regression equation based on these values. The slope of the equation informs us that his CS is 5.74 m/s, and the y-intercept informs us that his D’ is 261.30 metres.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/Tokyo-olympics-1500m-analysis/image3.webp" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Estimation of critical speed and work capacity from a distance-duration graph</figcaption><p></p>
</figure>
</div>
</section>
<section id="application-of-the-critical-speed-concept-to-pacing" class="level2">
<h2 class="anchored" data-anchor-id="application-of-the-critical-speed-concept-to-pacing">Application of the critical speed concept to pacing</h2>
<p>In the recent American College of Sports Medicine 2021 Annual Meeting, a <a href="https://journals.lww.com/acsm-msse/Fulltext/2021/08001/Pacing_Strategy_In_One_mile_World_Records_As_A.152.aspx"><u>research study</u></a> demonstrated that 1-mile (1600m) world record performances were ran above CS with complete depletion of D’ at the finish line. Since running 1500m is likely akin to running a mile, it is interesting to find out how 1500m event athletes paced themselves in respect to their CS and D’. This blog post examined the pacing profiles of both male and female runners who competed in the 1500m finals at the Tokyo Olympics, whereby runners fought for podium positions instead of world records.</p>
<p>I adopted the same approach as the research study to calculate the CS and D’ of all the athletes. Data of individual personal best performances between 800-5000m were extracted from the IAAF database, and the linear regression method was used to derive the CS and D’. Given that very old records may not reflect the athlete’s current fitness level accurately, personal bests achieved before 2014 were excluded from the calculation.</p>




<meta charset="utf-8">
<style>body{background-color:white;}</style>




<div id="dqwupufglr" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
  <style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#dqwupufglr .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#dqwupufglr .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#dqwupufglr .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#dqwupufglr .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#dqwupufglr .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#dqwupufglr .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#dqwupufglr .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#dqwupufglr .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#dqwupufglr .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#dqwupufglr .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#dqwupufglr .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#dqwupufglr .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#dqwupufglr .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#dqwupufglr .gt_from_md > :first-child {
  margin-top: 0;
}

#dqwupufglr .gt_from_md > :last-child {
  margin-bottom: 0;
}

#dqwupufglr .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#dqwupufglr .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#dqwupufglr .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#dqwupufglr .gt_row_group_first td {
  border-top-width: 2px;
}

#dqwupufglr .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#dqwupufglr .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#dqwupufglr .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#dqwupufglr .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#dqwupufglr .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#dqwupufglr .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#dqwupufglr .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#dqwupufglr .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#dqwupufglr .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#dqwupufglr .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-left: 4px;
  padding-right: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#dqwupufglr .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#dqwupufglr .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#dqwupufglr .gt_left {
  text-align: left;
}

#dqwupufglr .gt_center {
  text-align: center;
}

#dqwupufglr .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#dqwupufglr .gt_font_normal {
  font-weight: normal;
}

#dqwupufglr .gt_font_bold {
  font-weight: bold;
}

#dqwupufglr .gt_font_italic {
  font-style: italic;
}

#dqwupufglr .gt_super {
  font-size: 65%;
}

#dqwupufglr .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 75%;
  vertical-align: 0.4em;
}

#dqwupufglr .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#dqwupufglr .gt_indent_1 {
  text-indent: 5px;
}

#dqwupufglr .gt_indent_2 {
  text-indent: 10px;
}

#dqwupufglr .gt_indent_3 {
  text-indent: 15px;
}

#dqwupufglr .gt_indent_4 {
  text-indent: 20px;
}

#dqwupufglr .gt_indent_5 {
  text-indent: 25px;
}
</style>
  <table class="gt_table">
<thead class="gt_header">
<tr>
<td colspan="6" class="gt_heading gt_title gt_font_normal gt_bottom_border" style=""><strong>Tokyo Olympics 1500m Finalists</strong></td>
</tr>

</thead>
<thead class="gt_col_headings">
<tr>
<th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col"></th>
<th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col">Critical Speed<br>(m/s)</th>
<th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col">Work Capacity<br>(m)</th>
<th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col">Result</th>
<th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col">Average Speed<br>(m/s)</th>
<th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col">Percentage of<br>Critical Speed<br>(%)</th>
</tr>
</thead>
<tbody class="gt_table_body">
<tr class="gt_group_heading_row">
<td colspan="6" class="gt_group_heading" style="border-top-width: 3px; border-top-style: solid; border-top-color: black; border-bottom-width: 3px; border-bottom-style: solid; border-bottom-color: black;">Male</td>
</tr>
<tr class="gt_row_group_first"><th scope="row" class="gt_row gt_left gt_stub">Jakob Ingebrigtsen</th>
<td class="gt_row gt_center">6.32</td>
<td class="gt_row gt_center">155.88</td>
<td class="gt_row gt_center">03:28:00</td>
<td class="gt_row gt_center">7.21</td>
<td class="gt_row gt_center">114.01</td></tr>
<tr><th scope="row" class="gt_row gt_left gt_stub">Timothy Cheruiyot</th>
<td class="gt_row gt_center">5.74</td>
<td class="gt_row gt_center">262.96</td>
<td class="gt_row gt_center">03:29:00</td>
<td class="gt_row gt_center">7.18</td>
<td class="gt_row gt_center">125.10</td></tr>
<tr><th scope="row" class="gt_row gt_left gt_stub">Abel Kipsang</th>
<td class="gt_row gt_center">5.98</td>
<td class="gt_row gt_center">199.07</td>
<td class="gt_row gt_center">03:29:00</td>
<td class="gt_row gt_center">7.18</td>
<td class="gt_row gt_center">120.00</td></tr>
<tr><th scope="row" class="gt_row gt_left gt_stub">Josh Kerr</th>
<td class="gt_row gt_center">5.85</td>
<td class="gt_row gt_center">194.94</td>
<td class="gt_row gt_center">03:29:00</td>
<td class="gt_row gt_center">7.18</td>
<td class="gt_row gt_center">122.66</td></tr>
<tr><th scope="row" class="gt_row gt_left gt_stub">Adel Mechaal</th>
<td class="gt_row gt_center">6.08</td>
<td class="gt_row gt_center">188.71</td>
<td class="gt_row gt_center">03:30:00</td>
<td class="gt_row gt_center">7.14</td>
<td class="gt_row gt_center">117.36</td></tr>
<tr><th scope="row" class="gt_row gt_left gt_stub">Stewart McSweyn</th>
<td class="gt_row gt_center">6.08</td>
<td class="gt_row gt_center">225.51</td>
<td class="gt_row gt_center">03:31:00</td>
<td class="gt_row gt_center">7.11</td>
<td class="gt_row gt_center">116.91</td></tr>
<tr><th scope="row" class="gt_row gt_left gt_stub">Cole Hocker</th>
<td class="gt_row gt_center">6.04</td>
<td class="gt_row gt_center">184.32</td>
<td class="gt_row gt_center">03:31:00</td>
<td class="gt_row gt_center">7.11</td>
<td class="gt_row gt_center">117.71</td></tr>
<tr><th scope="row" class="gt_row gt_left gt_stub">Michal Rozmys</th>
<td class="gt_row gt_center">5.70</td>
<td class="gt_row gt_center">240.19</td>
<td class="gt_row gt_center">03:32:00</td>
<td class="gt_row gt_center">7.08</td>
<td class="gt_row gt_center">124.13</td></tr>
<tr><th scope="row" class="gt_row gt_left gt_stub">Jake Heyward</th>
<td class="gt_row gt_center">5.93</td>
<td class="gt_row gt_center">199.59</td>
<td class="gt_row gt_center">03:34:00</td>
<td class="gt_row gt_center">7.01</td>
<td class="gt_row gt_center">118.12</td></tr>
<tr><th scope="row" class="gt_row gt_left gt_stub">Oliver Hoare</th>
<td class="gt_row gt_center">6.02</td>
<td class="gt_row gt_center">145.21</td>
<td class="gt_row gt_center">03:35:00</td>
<td class="gt_row gt_center">6.98</td>
<td class="gt_row gt_center">116.00</td></tr>
<tr><th scope="row" class="gt_row gt_left gt_stub">Jake Wightman</th>
<td class="gt_row gt_center">5.60</td>
<td class="gt_row gt_center">264.12</td>
<td class="gt_row gt_center">03:35:00</td>
<td class="gt_row gt_center">6.98</td>
<td class="gt_row gt_center">124.55</td></tr>
<tr><th scope="row" class="gt_row gt_left gt_stub">Charles Grethen</th>
<td class="gt_row gt_center">5.70</td>
<td class="gt_row gt_center">227.81</td>
<td class="gt_row gt_center">03:36:00</td>
<td class="gt_row gt_center">6.94</td>
<td class="gt_row gt_center">121.70</td></tr>
<tr><th scope="row" class="gt_row gt_left gt_stub">Ignacio Fontes</th>
<td class="gt_row gt_center">5.44</td>
<td class="gt_row gt_center">266.54</td>
<td class="gt_row gt_center">03:38:00</td>
<td class="gt_row gt_center">6.88</td>
<td class="gt_row gt_center">126.51</td></tr>
<tr class="gt_group_heading_row">
<td colspan="6" class="gt_group_heading" style="border-top-width: 3px; border-top-style: solid; border-top-color: black; border-bottom-width: 3px; border-bottom-style: solid; border-bottom-color: black;">Female</td>
</tr>
<tr class="gt_row_group_first"><th scope="row" class="gt_row gt_left gt_stub">Faith Kipyegon</th>
<td class="gt_row gt_center">5.55</td>
<td class="gt_row gt_center">181.89</td>
<td class="gt_row gt_center">03:53:00</td>
<td class="gt_row gt_center">6.44</td>
<td class="gt_row gt_center">116.00</td></tr>
<tr><th scope="row" class="gt_row gt_left gt_stub">Laura Muir</th>
<td class="gt_row gt_center">5.40</td>
<td class="gt_row gt_center">203.50</td>
<td class="gt_row gt_center">03:54:00</td>
<td class="gt_row gt_center">6.41</td>
<td class="gt_row gt_center">118.61</td></tr>
<tr><th scope="row" class="gt_row gt_left gt_stub">Sifan Hassan</th>
<td class="gt_row gt_center">5.63</td>
<td class="gt_row gt_center">167.16</td>
<td class="gt_row gt_center">03:55:00</td>
<td class="gt_row gt_center">6.38</td>
<td class="gt_row gt_center">113.31</td></tr>
<tr><th scope="row" class="gt_row gt_left gt_stub">Freweyni Gebreezibeher<sup class="gt_footnote_marks">1</sup></th>
<td class="gt_row gt_center">5.88</td>
<td class="gt_row gt_center">111.76</td>
<td class="gt_row gt_center">03:57:00</td>
<td class="gt_row gt_center">6.33</td>
<td class="gt_row gt_center">107.61</td></tr>
<tr><th scope="row" class="gt_row gt_left gt_stub">Gabriela Debues-Stafford</th>
<td class="gt_row gt_center">5.48</td>
<td class="gt_row gt_center">163.58</td>
<td class="gt_row gt_center">03:58:00</td>
<td class="gt_row gt_center">6.30</td>
<td class="gt_row gt_center">114.97</td></tr>
<tr><th scope="row" class="gt_row gt_left gt_stub">Linden Hall</th>
<td class="gt_row gt_center">5.23</td>
<td class="gt_row gt_center">211.84</td>
<td class="gt_row gt_center">03:59:00</td>
<td class="gt_row gt_center">6.28</td>
<td class="gt_row gt_center">120.05</td></tr>
<tr><th scope="row" class="gt_row gt_left gt_stub">Winnie Nanyondo</th>
<td class="gt_row gt_center">4.94</td>
<td class="gt_row gt_center">262.28</td>
<td class="gt_row gt_center">03:59:00</td>
<td class="gt_row gt_center">6.28</td>
<td class="gt_row gt_center">127.25</td></tr>
<tr><th scope="row" class="gt_row gt_left gt_stub">Nozomi Tanaka</th>
<td class="gt_row gt_center">5.40</td>
<td class="gt_row gt_center">156.39</td>
<td class="gt_row gt_center">03:59:00</td>
<td class="gt_row gt_center">6.28</td>
<td class="gt_row gt_center">116.35</td></tr>
<tr><th scope="row" class="gt_row gt_left gt_stub">Marta Perez</th>
<td class="gt_row gt_center">4.96</td>
<td class="gt_row gt_center">248.97</td>
<td class="gt_row gt_center">04:00:00</td>
<td class="gt_row gt_center">6.25</td>
<td class="gt_row gt_center">125.93</td></tr>
<tr><th scope="row" class="gt_row gt_left gt_stub">Elinor Purrier St. Pierre</th>
<td class="gt_row gt_center">5.37</td>
<td class="gt_row gt_center">176.30</td>
<td class="gt_row gt_center">04:01:00</td>
<td class="gt_row gt_center">6.22</td>
<td class="gt_row gt_center">115.78</td></tr>
<tr><th scope="row" class="gt_row gt_left gt_stub">Jessica Hull</th>
<td class="gt_row gt_center">5.50</td>
<td class="gt_row gt_center">154.55</td>
<td class="gt_row gt_center">04:02:00</td>
<td class="gt_row gt_center">6.20</td>
<td class="gt_row gt_center">112.78</td></tr>
<tr><th scope="row" class="gt_row gt_left gt_stub">Cory Ann McGee</th>
<td class="gt_row gt_center">4.92</td>
<td class="gt_row gt_center">269.57</td>
<td class="gt_row gt_center">04:05:00</td>
<td class="gt_row gt_center">6.12</td>
<td class="gt_row gt_center">124.33</td></tr>
<tr><th scope="row" class="gt_row gt_left gt_stub">Kristiina Maki</th>
<td class="gt_row gt_center">5.19</td>
<td class="gt_row gt_center">197.79</td>
<td class="gt_row gt_center">04:11:00</td>
<td class="gt_row gt_center">5.98</td>
<td class="gt_row gt_center">115.13</td></tr>
</tbody>
<tfoot class="gt_sourcenotes">
<tr>
<td class="gt_sourcenote" colspan="6">Table: @nxrunning | Data: Tokyo Olympics 2020 &amp; IAAF Database</td>
</tr>
</tfoot>
<tfoot class="gt_footnotes">
<tr>
<td class="gt_footnote" colspan="6"><sup class="gt_footnote_marks">1</sup> CS and D' values are likely inaccurate due to only two personal best records available</td>
</tr>
</tfoot>
</table>
</div>


<p>The table above presents the CS and D’ values of all 1500m event finalists. Ingebrigtsen and Gebreezibeher have the highest CS values among the males and females, respectively. However, please note that the prediction of CS and D’ for Gebreezibeher may be potentially erroneous due to availability of only two personal best records. In terms of D’, Wightman and McGee possess the highest values within their gender groups. This table clearly suggests that physiology in the context of CS and D’ values can differ among runners at such elite levels.</p>
<p>The table also informs us the performances of all runners in the finals. As expected, the intensities of the race for both gender groups were beyond CS. On average, athletes ran at approximately 18% above their CS, which corresponds to a speed that diminished 0.51% of their D’ every second.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/Tokyo-olympics-1500m-analysis/image4.webp" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Pacing profiles of the top 6 athletes in the Tokyo Olympics Women’s 1500m Finals</figcaption><p></p>
</figure>
</div>
</section>
<section id="analysis-of-womens-race" class="level2">
<h2 class="anchored" data-anchor-id="analysis-of-womens-race">Analysis of Women’s Race</h2>
<p>The women’s race was won in 03:53.1 by defending champion, Kipyegon. The silver and bronze medals went to Muir and Hassan, respectively. The figure above presents the pacing behaviours exhibited by the top 6 finishers. All female runners ran at a speed above CS throughout the race, and majority paced themselves in a manner whereby D’ was completely depleted towards the end of the race.</p>
<p>All runners started the race relatively close together in a pack and went through the first two laps at approximately 63-65 seconds per 400m. As illustrated in the figure above, the intensity of such pace can be different among the athletes due to their contrasting CS. For example, this pace corresponded to about 20% above CS for Hall while the same running speed was about 15% above CS for Kipyegon instead, who has a more superior CS. This suggests that Hall was working harder as compared to Kipyegon at similar running pace. At the same time, this also means that Hall was diminishing her D’ at a faster rate than Kipyegon. Interestingly, despite Hall having greater D’ (209.39m) than Kipyegon (180.47m), the rate of her D’ decline was greater than Kipyegon due to her lower CS. This suggests that Hall was less likely to sustain the same pace as compared to Kipyegon. The running pack broke into two groups 1000m into the race and Hall expectedly had a difficult time hanging on to the leading group.</p>
<p>The critical section of the race was at the 1200m mark, in which runners tend to compete for the final sprint to the finish line. As purported by the concept of CS, information on remaining D’ may tell us the ability of athletes to further push their pace as well as the sustainability of their efforts. The medallists had greater D’ remaining and led the charge in the last lap, with Kipyegon and Muir running the section between 1200 and 1400m at an impressive speed of 27% above CS. In contrast, as shown in the figure, Debues-Stafford started slowing beyond 1200m as her D’ went into the negatives. By the 1400m mark, 5 out of the front 6 runners had emptied their tanks and slowing down of the speed for the final 100m was observed.</p>
<p>The figure also highlights certain disagreements between our predictions and actual performances. First, based on the figure, Gebreezibeher ran the entire race at the lowest %CS and had the highest %D’ remaining. However, she was not able to sustain her running speed in the last 100m despite her D’ not completely depleted. This is likely attributed to the inaccuracy of her CS and D’ values being calculated due to lack of available data. The performance suggests that she likely has either lower CS or D’ than what was estimated. Second, the data also informs us that Hassan was expected to sustain the pace that Kipyegon and Muir ran in the last lap. Based on Kipyegon’s running speed of 7.07m/s and their respective remaining D’ values, Kipyegon, Hassan and Muir were estimated to sustain that pace for approximately 20.9s, 20.7s and 15.6s, respectively. However, Muir ‘overperformed’ while Hassan ‘underperformed’ in the race. Obviously, such disagreement could be due to a myriad of other factors that may influence the race performance as well as the inaccuracy of the CS and D’ estimation.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/Tokyo-olympics-1500m-analysis/image5.webp" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Pacing profiles of the top 6 athletes in the Tokyo Olympics Men’s 1500m Finals</figcaption><p></p>
</figure>
</div>
</section>
<section id="analysis-of-mens-race" class="level2">
<h2 class="anchored" data-anchor-id="analysis-of-mens-race">Analysis of Men’s Race</h2>
<p>The men’s race was a crackling race with top 6 finishers smashing the Olympics record. Ingebrigtsen won the race in 03:28.3 and was accompanied by Cheruiyot and Kerr on the podium. The pacing profiles of the top 6 runners are presented in the figure above. Similarly, we observe a general trend in which runners ran at a speed above CS throughout the race with complete depletion of D’ towards the end of the race.</p>
<p>Among the top 6 competitors, Cheruiyot started the race at the highest percentage above CS. Although he was working at a relatively higher intensity, his superior D’ compensates for his efforts and he had the highest absolute remaining D’ in the earlier stages of the race. This highlights the importance of examining an individual’s workload with respect to both CS and D’ together to predict fatigue accurately.</p>
<p>Cheruiyot initiated the sprint in the last lap at a pace 25% above his CS, but he was unable to sustain his efforts over the last 100m. Ingebrigtsen displayed his superior physiology as he matched Cheruiyot’s pace and managed to maintain that through the finish line. This suggests that Ingebrigtsen’s present fitness level is likely higher than what we have estimated. Another surprising performance was from Kerr, who was the bronze medallist. As shown in the figure, his average effort over the race was 24% above his estimated CS and he was predicted to empty his tank by 1200m mark. However, he showed an incredible performance in the last lap, running at a speed faster than Cheruiyot and Ingebrigtsen. Based on his estimated D’, his actual efforts would have over-depleted his D’ by 44%. Certainly, he is way fitter than what was estimated.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>This blog post has demonstrated the use of the critical speed concept to gain meaningful insights into athlete’s pacing behaviour in the 1500m event. Knowledge of one’s CS and D’ allows us to estimate how hard the athlete is working, and how long he or she can sustain such high-intensity efforts. Albeit a difficult task, accurate information of competitors’ CS and D’ values can help to inform optimal pacing strategy during the race. At the end of the day, the athlete with the most superior physiology tends to win the race, and the concept of critical speed helps us to understand why is it so.</p>
<p>All analysis and visualisations were performed using R programming. You may access the data and codes at my <a href="https://github.com/nxrunning/codelibrary/tree/Tokyo-Olympics-1500m-Analysis"><u>github</u></a>.</p>


</section>

 ]]></description>
  <category>Sport science</category>
  <guid>https://nienxiangtou.com/posts/Tokyo-olympics-1500m-analysis/index.html</guid>
  <pubDate>Sun, 08 Aug 2021 16:00:00 GMT</pubDate>
  <media:content url="https://nienxiangtou.com/posts/Tokyo-olympics-1500m-analysis/image.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>All about that Bayes: Why individuals appraise similar evidence differently?</title>
  <dc:creator>Nien Xiang Tou</dc:creator>
  <link>https://nienxiangtou.com/posts/All-about-that-bayes/index.html</link>
  <description><![CDATA[ 



<p>The world is intrinsically ambiguous, and we usually must make decisions and judgements in our daily lives in the face of uncertainty. Some situations are trivial (e.g., should I bring an umbrella? Can I get a prize from the claw machine?) while some can have heavy consequences (e.g., should I consent to a major surgery? Do I take the covid-19 vaccine?). Probability often guides our decisions in such instances. This article presents how Bayesian inference helps us in reasoning everyday problems and explains why different individuals appraise similar evidence differently.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/All-about-that-bayes/image.webp" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Source: Unsplash</figcaption><p></p>
</figure>
</div>
<section id="probability" class="level2">
<h2 class="anchored" data-anchor-id="probability">Probability</h2>
<p>Many of us should be familiar with the concept of probability, which refers to the likelihood of an event occurring. Probability of any event can be simply calculated by dividing the number of events of interest by the total number of possible outcomes. For example, the probability of attaining a 4 in a six-sided dice roll is 1/6. Given the assumption that the dice is fair, this implies that you expect to roll a 4 in every six rolls.</p>
<p>Computation of probability is relatively easy when parameters are known. However, this is usually not the case for many situations in our daily lives, in which the parameters are unknown to us. For instance, the probability of winning a prize from a claw machine is harder to ascertain as compared to the dice roll example. Typically, these machines have an operator-adjustable pay out rate that is unknown to players. Thus, how do we determine the probability of receiving a prize from a claw machine?</p>
<p>We may examine n number of trials and record the number of times a player successfully wins a prize. For example, we may observe that a player manages to win 2 prizes in a total of 25 trials. Given such observation, we may infer that the probability of winning is 2/25 or 8%.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/All-about-that-bayes/image2.webp" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Probability density function and cumulative distribution function graphs</figcaption><p></p>
</figure>
</div>
<p>We may also model the probability as a continuum using the beta distribution. The beta distribution is a probability distribution on probabilities, defined using two parameters: α and β. In the context of this illustration, α refers to the number of times a prize was won from the claw machine (i.e., 2) and β represents the number of times that a prize was not won (i.e., 23). The figure above presents the probability density function and cumulative distribution function of the beta distribution. The graph on the left informs us that most of the plot’s density is less than 0.2, and we can estimate the 95% confidence interval of the win rate to be approximately between 1% and 21% using the graph on the right. These numbers strongly suggest that the actual likelihood of winning a prize from this claw machine is 20% or less. While it is impossible to deduce the true win rate, both graphs certainly provided more information than a discrete probability value.</p>
<p>This approach of observing data and determining the probability of an event occurrence is commonly used in academia and taught in schools. Such interpretation of probability is also known as frequentist inference. As defined by <a href="https://en.wikipedia.org/wiki/Frequentist_inference"><u>Wikipedia</u></a>, this method of inference “draws conclusions from sample data by emphasizing the frequency or proportion of the data”. While this may be an objective way of quantifying uncertainty and likelihood, it does not align with how we behave and reason things in our daily lives. For example, given our calculated probability on winning the claw machine above, there are people who may decide to take their chances and others who refrain from it despite seeing the same evidence. The limitation of the frequentist school of thought is the lack of account for differing prior beliefs among different individuals.</p>
</section>
<section id="bayesian-inference-quantifying-and-updating-our-beliefs" class="level2">
<h2 class="anchored" data-anchor-id="bayesian-inference-quantifying-and-updating-our-beliefs">Bayesian inference: Quantifying and updating our beliefs</h2>
<p>In our daily lives, probability is not only used to describe data but also a way to quantify the strength of our beliefs in things about the world (e.g., I think the sun is likely to rise tomorrow, I am confident that the company will still exist in ten years’ time). Our beliefs change consistently as we experience new things and observe new evidence. Another school of thought, Bayesian inference, reflects exactly such process of quantifying and updating our beliefs.</p>
<p>The term “Bayesian” originated from an English statistician and Presbyterian minister, Thomas Bayes. He devised the Bayes’ Theorem, which is a concept of conditional probability defined by the formula below. P(A|B) refers to the probability that event A occurs given that event B has already occurred. Bayes Theorem purports that we can work out the probability of P(B|A) if we know the reversed conditional probability, P(A|B).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/All-about-that-bayes/image3.webp" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Bayes’ Theorem</figcaption><p></p>
</figure>
</div>
<p>The approach of using Bayes Theorem for subjective probability-based inference was instead popularized by a French scholar, Pierre-Simon Laplace. Such method of inference is termed Bayesian inference, which expresses how the probability of a hypothesis or state of belief should change given new evidence. Now, let us adapt the Bayes Theorem to the context of hypothesis (H) and observed evidence (E).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/All-about-that-bayes/image4.webp" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Application of Bayes’ Theorem to Bayesian inference</figcaption><p></p>
</figure>
</div>
<p>In the context of Bayesian inference, P(H|E) is referred to as the posterior probability, which represents how strongly we believe in our hypotheses given the evidence we observed. This can be derived using two key components: the likelihood, and the prior probability. First, the likelihood, P(E|H), represents the probability of the evidence given our hypothesis. This component is akin to how we calculate probability using the frequentist approach. Second, the prior probability, P(H), denotes the strength of our belief in our hypothesis before we observed the evidence. This is the key component that separates the frequentist and Bayesian inference approach. Last, we need P(E) to normalize our posterior probability to a value between 0 and 1.</p>
</section>
<section id="example-what-is-the-probability-of-covid-19-infection-if-you-have-a-positive-antigen-rapid-test" class="level2">
<h2 class="anchored" data-anchor-id="example-what-is-the-probability-of-covid-19-infection-if-you-have-a-positive-antigen-rapid-test">Example: What is the probability of Covid-19 infection if you have a positive antigen rapid test?</h2>
<p>Let us suppose you are in Singapore and you are tested positive for Covid-19 infection using an antigen rapid test (ART). As reported in this <a href="https://www.straitstimes.com/singapore/false-positives-or-negatives-and-their-impact-on-mass-testing">news article</a>, the ART’s sensitivity (true positive rate) is 82% and its specificity (true negative rate) is 99%. This also indicates that the false positive rate is 1%. Given that we googled and found that the rate of Covid-19 infection in Singapore is approximately 1% at present, what is the probability of infection if you receive a positive swab test?</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/All-about-that-bayes/image5.webp" class="img-fluid figure-img"></p>
</figure>
</div>
<p>The table above informs us that the probability of infection is 45.3% after accounting for our prior belief that the rate of infection is 1%. This example also highlights the difference in inference between a frequentist and Bayesian approach. If we do not account for any prior probability, we would have assumed that the probability of infection is equivalent to the likelihood of 82% since that is the true positive rate of the test.</p>
<p>Now, let us examine the difference in posterior probability if we have a different prior probability. For example, if somebody hypothesizes that the infection rate is higher at 5%, what is the probability of infection given a positive swab test?</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/All-about-that-bayes/image6.webp" class="img-fluid figure-img"></p>
</figure>
</div>
<p>As presented in the new table, the new posterior probability increases to 81.2%. Given the same evidence, one who has a higher prior probability is more certain of infection as compared to somebody who has a lower prior probability. This may have implications on mental health since fear and anxiety levels probably differ between 45% and 81% chance of infection.</p>
</section>
<section id="updating-our-beliefs" class="level2">
<h2 class="anchored" data-anchor-id="updating-our-beliefs">Updating our beliefs</h2>
<p>The heart of Bayesian inference is the concept of updating our beliefs as we gather new evidence. Importantly, this is a continuous process. Let us take our example one step further and suppose that we took the ART a second time and tested positive again. What will be our new posterior probability?</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/All-about-that-bayes/image7.webp" class="img-fluid figure-img"></p>
</figure>
</div>
<p>We change our prior probability to 45.3% based on the first test result and calculate the posterior probability again. The table above informs us that the updated odds of infection is 98.5%. Clearly, we should go to the hospital immediately!</p>
</section>
<section id="prior-beliefs-matter" class="level2">
<h2 class="anchored" data-anchor-id="prior-beliefs-matter">Prior beliefs matter</h2>
<p>The use of Bayes Theorem demonstrates the importance of prior beliefs in appraising the same evidence. Many of our beliefs and hypotheses about the world differ from person to person. As illustrated in the example, different prior beliefs can result in contrasting posterior probabilities. This plausibly explains why individuals appraise similar evidence differently and thus different behaviours. Thus, it is important to note that probability does not just describe randomness, but also expresses strength of individual beliefs, and their interaction informs our decisions and judgements in daily lives.</p>


</section>

 ]]></description>
  <category>Statistics</category>
  <guid>https://nienxiangtou.com/posts/All-about-that-bayes/index.html</guid>
  <pubDate>Wed, 03 Mar 2021 16:00:00 GMT</pubDate>
  <media:content url="https://nienxiangtou.com/posts/All-about-that-bayes/image.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>Radar charts in R: Visualising playing styles of EPL football teams</title>
  <dc:creator>Nien Xiang Tou</dc:creator>
  <link>https://nienxiangtou.com/posts/Radar-charts-football-visualisation/index.html</link>
  <description><![CDATA[ 



<p>Playing styles typically differed among football teams. A team’s playing style is often based on a myriad of factors including manager’s football philosophy, tactical strategies, players’ attributes etc. This blog post visualises the playing styles of English Premier League (EPL) football teams with the use of radar charts.</p>
<section id="characterising-playing-styles" class="level2">
<h2 class="anchored" data-anchor-id="characterising-playing-styles">Characterising Playing Styles</h2>
<p>While it is common to hear that certain teams are either predominantly attacking or defensively minded, such descriptions often sound quite vague. Thanks to <a href="http://understat.com/"><u>Understat</u></a>, we can use data to try characterising playing styles of football teams in a more objective manner. The <em>understatr</em> package provides match statistics on several major European football leagues from previous seasons, saving us the trouble from performing web scrapping ourselves. In this blog post, three key statistics were used to characterise the match plays of football teams in EPL season 19/20: passes allowed per defensive action (PPDA), deep, and expected goals (xG).</p>
<p>First, PPDA is a measure of a team’s high press intensity and it is calculated using the number of passes made by the attacking team divided by the number of defensive actions (e.g.&nbsp;tackle, interception, challenge, foul). A high pressing team will be expected to have lower PPDA values since pressing strategies will result in greater number of defensive actions and diminish the likelihood of the opposition team stringing many passes successfully. Hence, low PPDA values indicate high intensity of pressing and vice versa.</p>
<p>Second, deep refers to the number of passes completed within an estimated 20 yards of goal, excluding crosses. This gives us insights on a team’s behaviour in the final third of the opposition team.</p>
<p>Last, xG provides information on the goal-scoring opportunities of a team. It represents the accumulative probability of shots being scored in a match. I have used this metric to examine Liverpool’s title-winning success in my <a href="https://www.nienxiangtou.com/posts/liverpool-success-lucky-or-worthy-winners/"><u>previous blog post</u></a>. In this blog post, the non-penalty expected goals (npxG) metric was used instead to specifically account for goal-scoring opportunities exclusive of penalties, which tend to have high xG values.</p>
</section>
<section id="radar-chart-visualisation" class="level2">
<h2 class="anchored" data-anchor-id="radar-chart-visualisation">Radar Chart Visualisation</h2>
<p>Radar charts are useful to visualise multivariate data in a two-dimensional manner. This is also a popular way in displaying football data. Statsbomb, a football analytics company, commonly uses such visualisation to show and compare individual players’ statistics. While there are different packages capable of creating radar charts, this blog post utilised the <em>ggradar</em> package to visualise the three aforementioned statistics.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/Radar-charts-football-visualisation/image2.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>The figure above is an example of a radar chart, which displays the three statistics for two different teams. All three variables were first standardised and rescaled to a range between 0 and 1 with reference to all the teams in the league. This is to ensure that different variables of differing scales could be mapped onto the same “axes”. As seen in the figure, the chart has three circular gridlines of different sizes and colours. These gridlines represent the common axes shared by all variables and correspond to the rescaled range in percentages. The most inner gridline, in yellow, corresponds to 0%. The middle gridline (in red) corresponds to 50% and the most outer gridline (in black) corresponds to 100%. Low scores on any of the variables are close to the yellow gridline and high scores are more proximal to the black gridline instead.</p>
<p>Radar charts are useful in helping us to make comparisons quickly. The radar chart above compares the match statistics between Liverpool FC and Newcastle United. The playing style of each team is defined in a triangular shape since we have three variables. With a glance of the chart, the contrast between the two triangles suggests that the playing styles differed between the two teams.</p>
<p>The radar chart shows that Liverpool scored above 50% for both npxG and deep statistics, and 0% for PPDA. Conversely, Newcastle scored very low on npxG and deep, but attained 100% for PPDA. Despite using only three variables, these statistics reveal insights on the differing styles between teams. Liverpool is a team that created relatively high number of goal scoring opportunities, and also made several passes in the opposition team’s final third. The 0% for PPDA indicates that they possessed the greatest intensity of high-pressing in the league. On the other hand, Newcastle is on the other end of the spectrum. 100% for PPDA suggests that they pressed relatively less than all the other teams in the league. In addition, they also made the least number of passes near the opposition’s goal. Unsurprisingly, their goal scoring opportunities were on the lower end (5.8%).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/Radar-charts-football-visualisation/image3.webp" class="img-fluid figure-img"></p>
</figure>
</div>
<p>Next, let’s compare between Liverpool and Manchester City. Contrary to the previous comparison, this radar chart clearly informs us that these two teams are very alike, as evidenced by the two almost similar triangles. Regular audience of the EPL would know that both teams like to be dominant in possession and play exciting attacking football. While they are similar, the runner-ups were superior in creating goal-scoring opportunities and passes in the opponent’s final third as compared to the champions. In fact, they were the best in both statistics across the entire league. On the other hand, Liverpool edged out their rivals in terms of high press intensity.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/Radar-charts-football-visualisation/image4.webp" class="img-fluid figure-img"></p>
</figure>
</div>
<p>Finally, the last figure presents the radar charts for every single team in the EPL, based on season 19/20 data. The teams are arranged in the order as the final table rankings. Interestingly, worst performing teams in terms of npxG (Crystal Palace), deep and PPDA (Newcastle) were not at the bottom of the league table. This suggests that these three indices are probably not the best predictors of overall football performance. Obviously, it would be somewhat too simplistic to characterise a team’s playing style merely on these three statistics. Nevertheless, they do provide us with some insights on different teams’ playing styles, and radar chart is a good approach to visualise these metrics and make comparisons with ease.</p>
<p>You may access the full code for all data processing and visualisation at my <a href="https://github.com/nxrunning/codelibrary/blob/EPLRadarChart/EPL_Radarchart.R"><u>github</u></a>.</p>


</section>

 ]]></description>
  <category>Data visualisation</category>
  <category>Football</category>
  <guid>https://nienxiangtou.com/posts/Radar-charts-football-visualisation/index.html</guid>
  <pubDate>Sat, 28 Nov 2020 16:00:00 GMT</pubDate>
  <media:content url="https://nienxiangtou.com/posts/Radar-charts-football-visualisation/image.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>The end spurt in marathon running: A universal behaviour?</title>
  <dc:creator>Nien Xiang Tou</dc:creator>
  <link>https://nienxiangtou.com/posts/End-spurt-in-marathon/index.html</link>
  <description><![CDATA[ 



<p>Pacing in endurance events is often characterised by an increase in power output or running speed towards the end, a behaviour termed the end spurt. This blog post examines the prevalence of such occurrence in Singaporean male and female runners during the Standard Chartered Singapore Marathon (SCSM) 2019.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/End-spurt-in-marathon/image.webp" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Sprint finish battle at the 2019 Boston Marathon. Source: Winslow Townson</figcaption><p></p>
</figure>
</div>
<section id="the-end-spurt" class="level2">
<h2 class="anchored" data-anchor-id="the-end-spurt">The End Spurt</h2>
<p>In the 2019 Boston Marathon, the fight for the first position in the men’s event came down to an epic sprint battle between Lawrence Cherono and Lelisa Desisa. Eventually, the winner and runner-up of an arduous 42.195 km race were separated by merely two seconds. The behaviour of increasing power output or running speed towards the end of an exercise bout is known as an end spurt. Such pacing behaviour is commonly observed in endurance events among both elite and recreational runners.</p>
<p>This observation has been of interest to sport scientists as it challenges the notion of fatigue. In an endurance event such as the marathon, it is expected that runners usually slow down as the distance progresses due to increase in fatigue levels. Thus, it is paradoxical that runners are able to speed up near the finish line when they are supposed to be the most fatigued. An explanation of such paradox is that individuals always exercise with reserves and regulate exercise in an anticipatory manner. As suggested in the central governor theory by renowned sport scientist, professor Timothy Noakes, anticipation is a critical component of exercise regulatory behaviour to avoid any catastrophic event happening during exercise.</p>
<p>Is such pacing behaviour exhibited by all runners?</p>
<p>My <a href="https://www.nienxiangtou.com/posts/pace-variation-in-marathon-running/">previous blog post</a> has examined the pace variation of Singaporean male and female runners of different levels who completed SCSM 2019. Using the same scraped data (see web scraping code <a href="https://github.com/nxrunning/codelibrary/blob/scsm-pacing-variation/webscrapingtimesplits">here</a>), this blog post examined the prevalence of the end spurt in both gender groups, and comparison was made among three groups of runners: fast, mid-pack and slow. The fast group represents the upper 20th percentile, the mid-pack consists of runners between the 40th and 60th percentile, and the slow group is made up of runners from the lower 20th percentile.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/End-spurt-in-marathon/image2.webp" class="img-fluid figure-img"></p>
</figure>
</div>
<p>First, let’s visualise the pacing profiles of each group of runners over the marathon distance, separated by gender. As illustrated in the figure above, the pacing profiles look quite similar across different groups. The observed pattern is characterised by an expected decrease in speed progressively over the course of the race. Interestingly, that is followed by an increase in speed right at the end of the race (last 2.195 km), demonstrating the end spurt behaviour. This seems to suggest that such behaviour can be observed in most runners regardless of their performance levels.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/End-spurt-in-marathon/image3.webp" class="img-fluid figure-img"></p>
</figure>
</div>
<p>To examine the prevalence of the end spurt, change in average speed between the last section and the average time split at 40 km was first computed. A positive change in speed means that runners ran faster during the last section as compared to their 40 km time splits, and a negative change in speed implies slowing down instead. As shown in the box plots above, the lower quartile is more than zero, indicating a positive change in speed was found in more than 75% of runners in both gender groups. Specifically, 88% of female runners and 86% of male runners increased their speed during the last 2.195 km of the marathon. This demonstrates that the end spurt behaviour was observed in majority of runners.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/End-spurt-in-marathon/image4.webp" class="img-fluid figure-img"></p>
</figure>
</div>
<p>While the pacing profiles above suggest that the end spurt behaviour was observed in all levels of runners, the degree of end spurt may differ between the groups. The figure above presents the change in speed as a percentage of the runners’ 40 km time split. Statistical analysis (one-way ANOVA and post-hoc pairwise comparisons) revealed that only the slow group differed from the other two groups for both genders. For the male runners, the increase in speed among the slower runners (8.05%) was significantly less than the mid-pack (12.88%) and the faster runners (13.05%). Similarly, for the female runners, the slow group (8.55%) sped up significantly less than the mid-pack (12.82%) and the fast group (11.44%). This suggests that better performing runners tend to speed up more than their slower peers during the last section of a marathon.</p>
</section>
<section id="anticipation-and-uncertainty" class="level2">
<h2 class="anchored" data-anchor-id="anticipation-and-uncertainty">Anticipation and Uncertainty</h2>
<p>These findings demonstrated that the end spurt behaviour in a marathon was highly prevalent among runners. Given that such behaviour was exhibited regardless of gender and performance levels, it has certainly interest me to further think about this phenomenon.</p>
<blockquote class="blockquote">
<p>Is the end spurt an innate manner of regulating endurance exercise?</p>
</blockquote>
<p>As mentioned earlier, a plausible explanation behind such phenomenon is that humans always exercise in an anticipatory manner. In most exercise settings, we are aware of the end point, be it expected distance or duration. Naturally, we want to reach this end point optimally and also safely as well. In the context of a marathon race, the performance goal is to reach the finish line as fast as possible. To achieve this, an athlete not only has to run at a fast pace, but also a sustainable one as well. In reality, this is a very challenging task because sustainability of pace is usually uncertain in an endurance event. This is supported by the variation in marathon running pace shown in my <a href="https://www.nienxiangtou.com/posts/pace-variation-in-marathon-running/">previous blog post</a>. However, this uncertainty diminishes with increasing proximity to the end point. For example, an athlete at the 10 km mark will be less confident of sustaining a given pace as compared to the athlete at 40 km instead. Rationally, an athlete will not select a pace that is knowingly unsustainable as that will be detrimental to performance. Therefore, it makes sense that individuals are only inclined to increase their pace when they know they are near to the finish line.</p>
<p>Comparison between different groups of runners showed us that better performing runners exhibited greater end spurts as compared to the slowest group. This either implies that 1) better runners were more conservative in their pacing and hence has greater reserve capacities to tap on for the final push, or 2) better runners were able to dig deeper than their slower counterparts and thus greater ability to speed up.</p>
<p>In summary, the end spurt is ubiquitous in an endurance event such as the marathon. It remains unclear why most individuals exhibit such behaviour. The next time you find yourself speeding up near the end of an exercise bout, I hope you can share with me your rationale behind it!</p>
<p>Data processing, analysis and visualisation were performed on R. Full code and datasets can be found <a href="https://github.com/nxrunning/codelibrary/tree/nxrunning-SCMS-endspurtprevalence">here</a>.</p>


</section>

 ]]></description>
  <category>Sport science</category>
  <guid>https://nienxiangtou.com/posts/End-spurt-in-marathon/index.html</guid>
  <pubDate>Tue, 28 Jul 2020 16:00:00 GMT</pubDate>
  <media:content url="https://nienxiangtou.com/posts/End-spurt-in-marathon/image.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>Liverpool’s success: Lucky or worthy winners?</title>
  <dc:creator>Nien Xiang Tou</dc:creator>
  <link>https://nienxiangtou.com/posts/Liverpool-success-lucky-or-worthy-winners/index.html</link>
  <description><![CDATA[ 



<p>Liverpool was announced the champions of English Premier League (EPL) season 19/20 with a record of seven games remaining. 23 points separate them from second-placed Manchester City. This post examines whether such overwhelming dominance over their rivals is attributed to sheer luck or genuine strength of the team through visualisation of expected goal data.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/Liverpool-success-lucky-or-worthy-winners/image.webp" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Source: This is Anfield</figcaption><p></p>
</figure>
</div>
<p>Football results do not necessarily reflect the performance of respective teams accurately. It is not always the case that the winning team has higher number of goal-scoring opportunities or greater possession than their opposition. Sometimes, teams walk away with a result merely due to good fortune. How do we differentiate between luck and performance?</p>
<section id="expected-goals" class="level2">
<h2 class="anchored" data-anchor-id="expected-goals">Expected Goals</h2>
<p>Evaluation of a team’s underlying performance at goal is made possible with the expected goals (xG) metric. The metric defines the probability of a shot being scored based on multiple factors such as angle, distance and type of assist. This is well-explained with various examples in the video link <a href="https://www.youtube.com/watch?v=w7zPZsLGK18&amp;feature=emb_logo">here</a> by Opta, a football data analytics company. Such measure provides us with further insights beyond the match statistics that are typically shown.</p>
<p>Football history has demonstrated that goals could be scored by players of different positions, including the goalkeeper. Some came from clear goal-scoring chances, while some were scored from very unexpected situations. For example, Asmir Begovic, goalkeeper of Stoke City, scored from his own penalty box in 2013. The xG metric would have informed us that the attempt had very low odds of hitting the back of the net. It is reasonable to consider that such abnormal and unexpected goals were just teams being lucky.</p>
<p>Theoretically, the team with better goal-scoring opportunities should register more goals. However, this is not the case in reality due to various factors and interaction effects in a football game. Therefore, comparison between expected and actual goals could help us differentiate chance occurrences and deserving performances. Scoring much more actual than expected goals would suggest a lucky outing for the team.</p>
<p>xG is not commonly reported because such information is not readily available online, as the probabilities are computed based on trained models using historical data. Some sites charge fees for these data. Fortunately, <a href="https://understat.com/">Understat.com</a> provides free access to xG statistics based on their algorithms. Data was scraped using BeautifulSoup package in python to examine whether Liverpool’s impressive season so far (31 fixtures) was a fluke or genuine prowess. You may find the web scraping code template on my github <a href="https://github.com/nxrunning/codelibrary/blob/nxrunning-webscrapingxGstatistics/Webscraping%20Understat%20based%20on%20football%20team.ipynb">here</a>.</p>
<p><img src="https://nienxiangtou.com/posts/Liverpool-success-lucky-or-worthy-winners/image2.webp" class="img-fluid"> The area plot above illustrates the comparison between actual and expected goals for Liverpool this season so far. The first important point is observing how xG approximates actual goals closely most of the time, which highlights the predictive value of the metric. Another interpretation of the plot is that Liverpool was expected to score at least one goal in most matches (29 to be precise). This is not surprising given that they are second in the league’s goal rankings. This suggests that Liverpool was quite consistent in producing goal-scoring opportunities.</p>
<p>The visible grey areas indicate that Liverpool registered more actual goals than expected in some occasions. While the disparity between the two areas is mostly quite small, such differences suggest that Liverpool had luck on their side on top of their performances. The most notable gap was on matchday 15, whereby Liverpool faced Everton in the Merseyside derby. Liverpool scored 5 goals, twice the xG statistic of 2.41. Aggregation of xG revealed that Liverpool was expected to score 64.25 goals, which is less than the 70 goals they actually scored.</p>
<p><img src="https://nienxiangtou.com/posts/Liverpool-success-lucky-or-worthy-winners/image3.webp" class="img-fluid"></p>
<p>Similarly, we could use the opposition’s xG metric to assess how lucky Liverpool was defensively. The figure above illustrates the comparison between actual and expected goals against. The visible blue areas indicate that Liverpool conceded less actual goals than expected, implying good fortune in these occasions. However, the visible red areas suggest that Liverpool was also unlucky during some fixtures as well. Aggregation of expected goals against revealed that Liverpool was expected to concede a total of 29.38 goals over 31 matches so far. In reality, Liverpool had the best defensive record in the league with a total of 21 conceded. Once again, the difference between the two measures suggests that luck was in Liverpool’s favour as well from the defensive perspective.</p>
<p><img src="https://nienxiangtou.com/posts/Liverpool-success-lucky-or-worthy-winners/image4.webp" class="img-fluid"></p>
</section>
<section id="expected-goal-difference" class="level2">
<h2 class="anchored" data-anchor-id="expected-goal-difference">Expected Goal Difference</h2>
<p>Subtracting the expected goals against from xG would compute the expected goal difference for a given fixture. The visualisation above presents the actual versus expected goal difference (xDiff) for all the fixtures. A positive xDiff indicates that the team should win the game, while negative xDiff indicates an expected loss, and zero implies an expected draw. This can inform us whether the team was deserving of its result.</p>
<p>According to the figure above, we could clearly see that Liverpool had a deserving loss on matchday 28. Liverpool lost convincingly to Watford by three goals. In that fixture, Liverpool registered their lowest xG of 0.21 and the highest expected goal against of 2.71. These statistics clearly showed that Liverpool had a very poor performance.</p>
<p>We could also use threshold values of +0.5 and -0.5 to determine whether Liverpool was anticipated to win and lose the game respectively based on their performance. The data revealed that 24 out of 31 games had an xDiff greater than 0.5, and only 2 out of 31 games had an xDiff less than -0.5. Such statistics strongly support Liverpool’s consistency in their performance throughout the season. In reality, Liverpool won a total of 28 games and lost 1 single game.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>In summary, xG is a valuable metric to assess the underlying performance of a team beyond the results. As the saying goes, better to be lucky than good. Indeed, the data revealed that Liverpool was lucky both offensively and defensively during certain occasions, albeit usually by small margins. However, saying that Liverpool’s success was a lucky win based on these results will be a complete misinterpretation. The xDiff data clearly shows that Liverpool exhibited strong performance consistently throughout the season and deserved their results. Therefore, a fair conclusion will be that Liverpool’s title winning success was largely attributed to their consistent strong performance, but they also had some luck on their side as well.</p>


</section>

 ]]></description>
  <category>Football</category>
  <category>Data visualisation</category>
  <guid>https://nienxiangtou.com/posts/Liverpool-success-lucky-or-worthy-winners/index.html</guid>
  <pubDate>Wed, 01 Jul 2020 16:00:00 GMT</pubDate>
  <media:content url="https://nienxiangtou.com/posts/Liverpool-success-lucky-or-worthy-winners/image.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>Spatial visualisation with ggmap: Covid-19 clusters in Singapore</title>
  <dc:creator>Nien Xiang Tou</dc:creator>
  <link>https://nienxiangtou.com/posts/Spatial-visualisation-covid-clusters-sgp/index.html</link>
  <description><![CDATA[ 



<p>Contact tracing plays a key role in infectious disease management, and related cases form a cluster. Since the coronavirus outbreak, several clusters have formed all over Singapore. This blog post documents my attempt to visualise the clusters on the Singapore map using R programming language.</p>
<section id="required-tools" class="level2">
<h2 class="anchored" data-anchor-id="required-tools">Required Tools</h2>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="fu" style="color: #4758AB;">library</span>(rvest)</span>
<span id="cb1-2"><span class="fu" style="color: #4758AB;">library</span>(ggplot2)</span>
<span id="cb1-3"><span class="fu" style="color: #4758AB;">library</span>(ggmap)</span></code></pre></div>
<p>Three libraries are required for this project. rvest does the web scraping and ggplot2 is required for graph plotting. More importantly, ggmap helps us to conveniently locate the coordinates of each cluster address with the geocode function.</p>
</section>
<section id="google-maps-api" class="level2">
<h2 class="anchored" data-anchor-id="google-maps-api">Google Maps API</h2>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><span class="fu" style="color: #4758AB;">register_google</span>(<span class="at" style="color: #657422;">key =</span> <span class="st" style="color: #20794D;">"insert your API key here"</span>)</span></code></pre></div>
<p>First, we need to register an authorised Google API key in order to use the <em>geocode</em> function. You may register for your free API key over <a href="https://cloud.google.com/maps-platform/terms/"><u>here</u></a>.</p>
</section>
<section id="cluster-list" class="level2">
<h2 class="anchored" data-anchor-id="cluster-list">Cluster List</h2>
<p>The list of clusters used in this blog post was from the <a href="https://co.vid19.sg/singapore/dashboard">Covid-19 Singapore Dashboard</a> created by Upcode Academy. The dashboard displays several visualisations on data related to the pandemic outbreak in Singapore. On the bottom right of the page, we could see the clusters and their respective number of cases. Data on the cluster list was scraped through the use of <em>rvest</em> package. The web scraping process is similar to the code I have documented in my <a href="https://www.nienxiangtou.com/posts/web-scraping-and-data-visualising-with-r-epl19/20-goal-stats/">previous blogpost</a>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/Spatial-visualisation-covid-clusters-sgp/image2.webp" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Organising the clusters into a data frame</figcaption><p></p>
</figure>
</div>
<p>A total of 47 clusters was scraped from the dashboard and organised into a dataframe. The figure above presents the name of each cluster and its respective number of cases. The list includes clusters that were identified early on during the outbreak (e.g.&nbsp;Yong Thai Hang medical shop, Grand Hyatt Hotel) as well as the foreign worker dormitories, where numbers have skyrocketed during the last 2 months (e.g.&nbsp;S11 Dormitory). Unfortunately, the numbers for certain clusters are not updated (especially for the dormitories). Nevertheless, it contains majority of the local clusters identified so far.</p>
<p>In order to plot each cluster on the map, we require the coordinates of each cluster address. Google identifies each address by its latitude and longitude position, which we can conveniently retrieve via the geocode function. Before doing this, we had to tidy up some of these cluster names in order to better locate them. For example, specifying “Grand Hyatt Hotel Singapore” instead of “Grand Hyatt Hotel” returns the local coordinates instead of a foreign location. Editing of all cluster names can be found in the full code.</p>
<p>A for-loop was then used to extract the coordinate positions for each cluster and appended to the data frame.</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><span class="co" style="color: #5E5E5E;"># Computing latitude and longitude of each location</span></span>
<span id="cb3-2"><span class="cf" style="color: #003B4F;">for</span> (i <span class="cf" style="color: #003B4F;">in</span> <span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">:</span><span class="fu" style="color: #4758AB;">nrow</span>(cluster_df)) {</span>
<span id="cb3-3">  cluster_name <span class="ot" style="color: #003B4F;">=</span> cluster_df[i, <span class="fu" style="color: #4758AB;">c</span>(<span class="st" style="color: #20794D;">"clusters"</span>)]</span>
<span id="cb3-4">  cluster_geocode <span class="ot" style="color: #003B4F;">=</span> <span class="fu" style="color: #4758AB;">geocode</span>(cluster_name)</span>
<span id="cb3-5">  cluster_df[i, <span class="fu" style="color: #4758AB;">c</span>(<span class="st" style="color: #20794D;">"lon"</span>)] <span class="ot" style="color: #003B4F;">&lt;-</span> cluster_geocode<span class="sc" style="color: #5E5E5E;">$</span>lon</span>
<span id="cb3-6">  cluster_df[i, <span class="fu" style="color: #4758AB;">c</span>(<span class="st" style="color: #20794D;">"lat"</span>)] <span class="ot" style="color: #003B4F;">&lt;-</span> cluster_geocode<span class="sc" style="color: #5E5E5E;">$</span>lat</span>
<span id="cb3-7">}</span></code></pre></div>
</section>
<section id="singapore-map" class="level2">
<h2 class="anchored" data-anchor-id="singapore-map">Singapore Map</h2>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><span class="co" style="color: #5E5E5E;"># Locating the latitude and longitude position of Singapore</span></span>
<span id="cb4-2"><span class="co" style="color: #5E5E5E;"># Lon = 103.8198, Lat = 1.352083</span></span>
<span id="cb4-3">singapore_city <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">geocode</span>(<span class="st" style="color: #20794D;">"Singapore"</span>)</span>
<span id="cb4-4"></span>
<span id="cb4-5"><span class="co" style="color: #5E5E5E;"># Retrieves the map image of the location</span></span>
<span id="cb4-6">singapore_map <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">get_map</span>(singapore_city, <span class="at" style="color: #657422;">zoom =</span> <span class="dv" style="color: #AD0000;">12</span>,  <span class="at" style="color: #657422;">maptype =</span> <span class="st" style="color: #20794D;">"roadmap"</span>)</span>
<span id="cb4-7"></span>
<span id="cb4-8"><span class="co" style="color: #5E5E5E;"># Visualising the map </span></span>
<span id="cb4-9"><span class="fu" style="color: #4758AB;">ggmap</span>(singapore_map)</span></code></pre></div>
<p>The map visualisation encompasses plotting each cluster on the map. Hence, we need to prepare the background map first. The coordinates of the map were retrieved through the geocode function. Next, the get_map function helps to get the image of the map. We could specify the amount of zoom as well as the map type. There are several map types, and “roadmap” represents the typical google map we see. Lastly, ggmap function helps us to visualise the map (see below).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/Spatial-visualisation-covid-clusters-sgp/image3.webp" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Visualisation of Singapore map using ggmap</figcaption><p></p>
</figure>
</div>
</section>
<section id="visualising-the-clusters" class="level2">
<h2 class="anchored" data-anchor-id="visualising-the-clusters">Visualising the clusters</h2>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><span class="co" style="color: #5E5E5E;"># Map the clusters on singapore map</span></span>
<span id="cb5-2"><span class="fu" style="color: #4758AB;">ggmap</span>(singapore_map, </span>
<span id="cb5-3">      <span class="at" style="color: #657422;">base_layer =</span> <span class="fu" style="color: #4758AB;">ggplot</span>(<span class="at" style="color: #657422;">data =</span> cluster_df,</span>
<span id="cb5-4">                          <span class="fu" style="color: #4758AB;">aes</span>(<span class="at" style="color: #657422;">x=</span>lon, <span class="at" style="color: #657422;">y =</span> lat, <span class="at" style="color: #657422;">color =</span> cases))) <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb5-5">  <span class="fu" style="color: #4758AB;">geom_point</span>(<span class="at" style="color: #657422;">size =</span> <span class="fl" style="color: #AD0000;">1.5</span>,</span>
<span id="cb5-6">             <span class="at" style="color: #657422;">alpha =</span> <span class="fl" style="color: #AD0000;">0.8</span>)<span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb5-7">  <span class="fu" style="color: #4758AB;">labs</span>(<span class="at" style="color: #657422;">title =</span> <span class="st" style="color: #20794D;">"Covid-19 Clusters in Singapore"</span>,</span>
<span id="cb5-8">       <span class="at" style="color: #657422;">caption =</span> <span class="st" style="color: #20794D;">"Data from Covid-19 Singapore Dashboard"</span>,</span>
<span id="cb5-9">       <span class="at" style="color: #657422;">color =</span> <span class="st" style="color: #20794D;">"Number of cases"</span>)<span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb5-10">  <span class="fu" style="color: #4758AB;">scale_colour_gradient</span>(<span class="at" style="color: #657422;">low =</span> <span class="st" style="color: #20794D;">"blue"</span>, <span class="at" style="color: #657422;">high =</span> <span class="st" style="color: #20794D;">"red"</span>, <span class="at" style="color: #657422;">na.value =</span> <span class="cn" style="color: #8f5902;">NA</span>)<span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb5-11">  <span class="fu" style="color: #4758AB;">theme_void</span>()</span></code></pre></div>
<p>Next, visualisation of the clusters was done by simply adding the scatterplot layer to the map layer. Specifying the color to be dependent on the number of cases helps to differentiate the magnitude of the clusters. You may set the gradient colours using scale_colour_gradient. In this case, most clusters are relatively small (&lt; 50) except the foreign worker dormitories. Unfortunately, as mentioned earlier, the numbers for the dormitories are not updated. You may see the final plot below. Do take note that certain clusters are missing from the plot due to the zoom size of the map selected.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/Spatial-visualisation-covid-clusters-sgp/image4.webp" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Map visualisation of Covid-19 clusters in Singapore using ggmap.</figcaption><p></p>
</figure>
</div>
<p>Full code for this article can be accessed through my <a href="https://gist.github.com/nxrunning/8cddd07506a90a8a9c29981abdf9bbed"><u>github</u></a>.</p>


</section>

 ]]></description>
  <category>Data visualisation</category>
  <guid>https://nienxiangtou.com/posts/Spatial-visualisation-covid-clusters-sgp/index.html</guid>
  <pubDate>Fri, 29 May 2020 16:00:00 GMT</pubDate>
  <media:content url="https://nienxiangtou.com/posts/Spatial-visualisation-covid-clusters-sgp/image.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>Pace variation in Marathon running: Analysing data from Standard Chartered Singapore Marathon 2019</title>
  <dc:creator>Nien Xiang Tou</dc:creator>
  <link>https://nienxiangtou.com/posts/Pace-variation-in-marathon-running/index.html</link>
  <description><![CDATA[ 



<p>Pacing strategy is an important determinant of performance, especially in endurance events such as the marathon. Does pacing profile differ across runners of different levels? This blog post examines the pace variation of Singaporean male and female runners in the Standard Chartered Singapore Marathon (SCSM) 2019.</p>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/Pace-variation-in-marathon-running/image.webp" width="680" height="400" class="figure-img"></p>
<p></p><figcaption class="figure-caption">SCMS 2019. Source: RunSociety.com</figcaption><p></p>
</figure>
</div>
<section id="art-of-pacing" class="level2">
<h2 class="anchored" data-anchor-id="art-of-pacing">Art of Pacing</h2>
<p>Pacing strategy in long-distance running refers to the distribution of running speed across the whole duration of event. Finding an optimised pacing strategy in a marathon event is no easy feat, as the distance often poses many uncertainties and unexpected challenges. Too conservative start may lead to a sub-optimal finish, while an aggressive start may result in early fatigue and excessive slowing down during latter stages of the race.</p>
<p>Generally, there are three types of pacing profiles: 1) negative, 2) positive, and 3) even pacing strategy. First, negative pacing refers to an increase in speed over the duration of event. This will mean running the second half of the race faster than the first half. Second, positive pacing is characterised by a decline in speed instead. Third, even pacing represents keeping relatively the same speed throughout the event. Such even pacing was observed in Eliud Kipchoge’s shattering of the 2 hour marathon barrier last year. If you look at his time <a href="https://www.flotrack.org/articles/6573663-eliud-kipchoge-shatters-two-hour-barrier-with-15940-marathon"><u>splits</u></a>, he and his pacing team ran each 5km within a range of 14:10 - 14:14. This suggests that adopting an even pacing profile in the marathon may be the most ideal strategy to hit your race goals.</p>
<p>Realistically, this is a tall order and gets increasingly harder to achieve as the race distance increases. Very often, we see drastic changes in running speed during endurance events. For example, we see more race participants walking in the second half of the marathon as compared to the first half. This is an expected phenomenon since fatigue kicks in as the race progresses. However, is such variation in pace similar across all levels of runners?</p>
<p>With the aim to answer this question, I scraped the time splits of all Singaporean runners who finished the full marathon in last year’s SCSM. The web scraping was performed using the pandas and BeautifulSoup package in python. You may find the full web scraping code <a href="https://github.com/nxrunning/codelibrary/blob/scsm-pacing-variation/webscrapingtimesplits">here</a>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/Pace-variation-in-marathon-running/image2.webp" class="img-fluid figure-img"></p>
</figure>
</div>
<p>Based on the official results from the race website, a total of 3929 Singaporean men and 911 women completed the full marathon. Clearly, the marathon is not as popular among females than their male counterparts. Data on each 5km time split was retrieved for each runner. However, several runners were found with missing data for certain distances. Hence, for runners with missing time splits, it was assumed that their pace remained the same as the last recorded time split. Runners with missing data for the first 5km and 10km were considered invalid and removed from the dataset. Thus, I ended up with a total of 3886 men and 902 women for the analysis.</p>
<p>The coefficient of variation (CV) was used to measure the variation in each runner’s pace throughout the race. This was simply computed by dividing the standard deviation of all time splits by the mean speed. Higher CVs represent greater variation in pace and lower CVs indicate more consistency in running speed throughout the race. The CV was compared among three groups of runners in both gender groups: fast, mid-pack and slow. The fast group represents the top 20%, the mid-pack represents the middle 20%, and the slow group represents the bottom 20%. The notched box plots above illustrate the average running speed distribution of each group separated by genders. Evidently, the speeds differed significantly across groups for both genders.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/Pace-variation-in-marathon-running/image3.webp" class="img-fluid figure-img"></p>
</figure>
</div>
<p>The graph above presents the average CV scores in percentages of respective groups for both genders. We can see a trend that pace variation increases with slower marathon running times. Using a statistical test (one-way ANOVA) informed us that the differences in pace variation across groups were significant. The top 20% Singaporean male runners had an average of 12.11% in their marathon pace variation, and this was significantly less than the mid-pack (14.93%) and the slow group (15.59%). However, the mid-pack and slow groups showed comparably similar variation in pace. Similarly, for the females, the fast group (8.14%) showed significantly less variation in their pace than their slower counterparts. The mid-pack group (12.8%) also differed significantly as compared to the slow group (15.32%).</p>
</section>
<section id="importance-of-consistency-in-pacing" class="level2">
<h2 class="anchored" data-anchor-id="importance-of-consistency-in-pacing">Importance of consistency in pacing</h2>
<p>These numbers highlighted that better performing runners were not only faster in their speed, they also exhibited considerably less variation in their marathon running pace. Obviously, many factors can influence a marathon performance. One aspect is definitely optimising your pacing strategy during the race. This means selecting a pace that you can sustain consistently with minimal variation throughout the race. This is an important takeaway for all levels of runners. Hence, do practise your pacing strategy during training, and carefully plan your pace for race day. It will probably make a difference!</p>
<p>Data processing, analysis and visualisation were performed on R. Full code and datasets can be found <a href="https://github.com/nxrunning/codelibrary/tree/scsm-pacing-variation"><u>here</u></a>.</p>


</section>

 ]]></description>
  <category>Sport science</category>
  <guid>https://nienxiangtou.com/posts/Pace-variation-in-marathon-running/index.html</guid>
  <pubDate>Fri, 15 May 2020 16:00:00 GMT</pubDate>
  <media:content url="https://nienxiangtou.com/posts/Pace-variation-in-marathon-running/image.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>Web Scraping Goodreads with BeautifulSoup: Popular runnning books</title>
  <dc:creator>Nien Xiang Tou</dc:creator>
  <link>https://nienxiangtou.com/posts/web-scraping-goodreads/index.html</link>
  <description><![CDATA[ 



<p>Data is incredibly important to every analyst or data scientist. Web scraping is a valuable skill that allows us to access the limitless sources of data online. In my previous <a href="https://www.nienxiangtou.com/posts/web-scraping-and-data-visualising-with-r-epl19/20-goal-stats/"><u>blogpost</u></a>, I have documented the use of R to scrape football data from a wikipedia page. This post presents my attempt on scraping information of popular running books from Goodreads using Python programming language.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/web-scraping-goodreads/image.webp" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Source: bookriot.com</figcaption><p></p>
</figure>
</div>
<section id="required-tools" class="level2">
<h2 class="anchored" data-anchor-id="required-tools">Required Tools</h2>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> requests</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">from</span> bs4 <span class="im" style="color: #00769E;">import</span> BeautifulSoup</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">from</span> urllib.parse <span class="im" style="color: #00769E;">import</span> urljoin</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> pandas <span class="im" style="color: #00769E;">as</span> pd</span></code></pre></div>
<p>We will require four library packages for this project. The <em>request</em> package helps with making HTTP requests from the website of interest. The <em>BeautifulSoup</em> package is a popular web scrapping python library and this helps us to perform the main work. The <em>urllib.parse</em> helps us to join URL addresses and the <em>pandas</em> library helps us to tidy the data scraped into a nice data frame.</p>
</section>
<section id="website" class="level2">
<h2 class="anchored" data-anchor-id="website">Website</h2>
<p>This <a href="https://www.goodreads.com/shelf/show/running"><u>page</u></a> on Goodreads presents the top 50 books related to running (see below). It showcases some information of each book such as the title, author names and ratings. However, if you want to read more detailed description of each book, you will have to click on the link of the book title.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/web-scraping-goodreads/image2.webp" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Screenshot of website</figcaption><p></p>
</figure>
</div>
</section>
<section id="set-up" class="level2">
<h2 class="anchored" data-anchor-id="set-up">Set up</h2>
<p>If you right click on most web pages, you may inspect its html codes. The codes are structured with several tags, classes and attributes that serve different purposes. Generally, web scraping locates the data that you are interested to extract based on information from these codes. The codes below help us to extract the website’s html and also create a BeautifulSoup object that we will further wrangle with. You may also examine the html file exported.</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;"># Specifying website url</span></span>
<span id="cb2-2">base_site <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"https://www.goodreads.com/shelf/show/running"</span> </span>
<span id="cb2-3"></span>
<span id="cb2-4"><span class="co" style="color: #5E5E5E;"># Make http request</span></span>
<span id="cb2-5">response <span class="op" style="color: #5E5E5E;">=</span> requests.get(base_site)</span>
<span id="cb2-6"></span>
<span id="cb2-7"><span class="co" style="color: #5E5E5E;"># Get the html from webpage</span></span>
<span id="cb2-8">html <span class="op" style="color: #5E5E5E;">=</span> response.content</span>
<span id="cb2-9"></span>
<span id="cb2-10"><span class="co" style="color: #5E5E5E;"># Creating a BeautifulSoup object with the use of a parser</span></span>
<span id="cb2-11">soup <span class="op" style="color: #5E5E5E;">=</span> BeautifulSoup(html, <span class="st" style="color: #20794D;">"lxml"</span>)</span>
<span id="cb2-12"></span>
<span id="cb2-13"><span class="co" style="color: #5E5E5E;"># Exporting html file</span></span>
<span id="cb2-14"><span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="st" style="color: #20794D;">'popularrunningbooks.html'</span>, <span class="st" style="color: #20794D;">'wb'</span>) <span class="im" style="color: #00769E;">as</span> <span class="bu" style="color: null;">file</span>:</span>
<span id="cb2-15">    <span class="bu" style="color: null;">file</span>.write(soup.prettify(<span class="st" style="color: #20794D;">'utf-8'</span>))</span></code></pre></div>
<p>The aim of this web scraping project was to extract relevant information regarding each of these 50 books: 1) book title, 2) author name(s), 3) book rating, 4) book pages, 5) book description. The general workflow to retrieve these information follows the same steps as if we were to manually do it. This involves us clicking on each of the book links and extract the data of interest. Hence, the very first step to help us automate this process is to extract this list of book links from the BeautifulSoup object we created earlier.</p>
<p>Html codes are generally built within many layers, similar to putting a present in several layers of gift boxes. Therefore, scraping data is akin to unwrapping the present layer by layer. Typically, a website’s content is hidden under the ‘div’ tag, which represents the outermost layer of the box. Hence, this is usually the starting point to unwrap our “present”. We could also specify the class and ID to help us better locate the data that we want. In this case, the book links are within the class “elementList”.</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;"># First layer: The element that contains all the data</span></span>
<span id="cb3-2">divs <span class="op" style="color: #5E5E5E;">=</span> soup.find_all(<span class="st" style="color: #20794D;">"div"</span>, {<span class="st" style="color: #20794D;">"class"</span>: <span class="st" style="color: #20794D;">"elementList"</span>})</span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="co" style="color: #5E5E5E;"># Second layer: Extracting html tags that contain the links</span></span>
<span id="cb3-5">links <span class="op" style="color: #5E5E5E;">=</span> [div.find(<span class="st" style="color: #20794D;">'a'</span>) <span class="cf" style="color: #003B4F;">for</span> div <span class="kw" style="color: #003B4F;">in</span> divs]</span></code></pre></div>
<p>The url information of each book links are located in the links. However, each of the url extracted is only a partial web address. For example, the corresponding partial url link for the book “Born to Run” looks like ‘/book/show/6289283-born-to-run’. In order to get the full url, we will use the <em>urljoin</em> method from the <em>urllib.parse</em> package to join our base site web address with each of these partial url links.</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;"># Extracting the partial links  </span></span>
<span id="cb4-2">relative_url <span class="op" style="color: #5E5E5E;">=</span> [link[<span class="st" style="color: #20794D;">'href'</span>] <span class="cf" style="color: #003B4F;">for</span> link <span class="kw" style="color: #003B4F;">in</span> links]  </span>
<span id="cb4-3"></span>
<span id="cb4-4"><span class="co" style="color: #5E5E5E;"># Computing the full url addresses </span></span>
<span id="cb4-5">full_url <span class="op" style="color: #5E5E5E;">=</span> [urljoin(base_site, relativeurl) <span class="cf" style="color: #003B4F;">for</span> relativeurl <span class="kw" style="color: #003B4F;">in</span> relative_url]</span></code></pre></div>
<p>If you inspect the full_url list , some unnecessary non-book links were accidentally extracted as well. Hence, the code below will help to overcome this problem.</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="co" style="color: #5E5E5E;"># Filter only the book links</span></span>
<span id="cb5-2">book_url <span class="op" style="color: #5E5E5E;">=</span> [url <span class="cf" style="color: #003B4F;">for</span> url <span class="kw" style="color: #003B4F;">in</span> full_url <span class="cf" style="color: #003B4F;">if</span> <span class="st" style="color: #20794D;">"https://www.goodreads.com/book/show"</span> <span class="kw" style="color: #003B4F;">in</span> url]</span></code></pre></div>
</section>
<section id="scraping-information-of-each-book" class="level2">
<h2 class="anchored" data-anchor-id="scraping-information-of-each-book">Scraping information of each book</h2>
<p>Finally, we have arrived at the main web scraping work. Imagine clicking on each of the book links and retrieve the data we need. Programming helps us to automate this process. First, we create five empty lists, whereby each list will store its respective information.</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">book_description <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb6-2">book_author <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb6-3">book_title <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb6-4">book_rating <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb6-5">book_pages <span class="op" style="color: #5E5E5E;">=</span> []</span></code></pre></div>
<p>The scraping process involves some similar steps stated earlier, whereby we have to retrieve the html code of each book link and locate the information we need. The same steps will be repeated for every link. The for-loop below helps us to perform this repetitive work.</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;">#creating a loop counter</span></span>
<span id="cb7-2">i <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb7-3"></span>
<span id="cb7-4"><span class="co" style="color: #5E5E5E;">#Loop through all 50 books</span></span>
<span id="cb7-5"><span class="cf" style="color: #003B4F;">for</span> url <span class="kw" style="color: #003B4F;">in</span> book_url:</span>
<span id="cb7-6">    </span>
<span id="cb7-7">    <span class="co" style="color: #5E5E5E;">#connect to url page</span></span>
<span id="cb7-8">    note_resp <span class="op" style="color: #5E5E5E;">=</span> requests.get(url)</span>
<span id="cb7-9">    </span>
<span id="cb7-10">    <span class="co" style="color: #5E5E5E;">#checking if the request is successful</span></span>
<span id="cb7-11">    <span class="cf" style="color: #003B4F;">if</span> note_resp.status_code <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">200</span>:</span>
<span id="cb7-12">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"URL</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">"</span>.<span class="bu" style="color: null;">format</span>(i<span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span>, url))</span>
<span id="cb7-13">    </span>
<span id="cb7-14">    <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb7-15">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Status code</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">: Skipping URL #</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">: </span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(note_resp.status_code, i<span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span>, url))</span>
<span id="cb7-16">        i <span class="op" style="color: #5E5E5E;">=</span> i<span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb7-17">        <span class="cf" style="color: #003B4F;">continue</span></span>
<span id="cb7-18">    </span>
<span id="cb7-19">    <span class="co" style="color: #5E5E5E;">#get HTML from url page</span></span>
<span id="cb7-20">    note_html <span class="op" style="color: #5E5E5E;">=</span> note_resp.content</span>
<span id="cb7-21">    </span>
<span id="cb7-22">    <span class="co" style="color: #5E5E5E;">#create beautifulsoup object for url page</span></span>
<span id="cb7-23">    note_soup <span class="op" style="color: #5E5E5E;">=</span> BeautifulSoup(note_html, <span class="st" style="color: #20794D;">'html.parser'</span>)</span>
<span id="cb7-24">    </span>
<span id="cb7-25">    <span class="co" style="color: #5E5E5E;">#Extract Author particulars</span></span>
<span id="cb7-26">    author_divs <span class="op" style="color: #5E5E5E;">=</span> note_soup.find_all(<span class="st" style="color: #20794D;">"div"</span>,{<span class="st" style="color: #20794D;">"class"</span>:<span class="st" style="color: #20794D;">"authorName__container"</span>})</span>
<span id="cb7-27">    author_text <span class="op" style="color: #5E5E5E;">=</span> author_divs[<span class="dv" style="color: #AD0000;">0</span>].find_all(<span class="st" style="color: #20794D;">'a'</span>)[<span class="dv" style="color: #AD0000;">0</span>].text</span>
<span id="cb7-28">    book_author.append(author_text)</span>
<span id="cb7-29">    </span>
<span id="cb7-30">    <span class="co" style="color: #5E5E5E;">#Extract title particulars</span></span>
<span id="cb7-31">    title_divs <span class="op" style="color: #5E5E5E;">=</span> note_soup.find_all(<span class="st" style="color: #20794D;">"div"</span>, {<span class="st" style="color: #20794D;">"class"</span>: <span class="st" style="color: #20794D;">"last col"</span>})</span>
<span id="cb7-32">    title_text <span class="op" style="color: #5E5E5E;">=</span> title_divs[<span class="dv" style="color: #AD0000;">0</span>].find_all(<span class="st" style="color: #20794D;">'h1'</span>)[<span class="dv" style="color: #AD0000;">0</span>].text</span>
<span id="cb7-33">    book_title.append(title_text)</span>
<span id="cb7-34">    </span>
<span id="cb7-35">    <span class="co" style="color: #5E5E5E;">#Extract rating particulars</span></span>
<span id="cb7-36">    rating_divs <span class="op" style="color: #5E5E5E;">=</span> note_soup.find_all(<span class="st" style="color: #20794D;">"div"</span>, {<span class="st" style="color: #20794D;">"class"</span>: <span class="st" style="color: #20794D;">"uitext stacked"</span>, <span class="st" style="color: #20794D;">"id"</span>: <span class="st" style="color: #20794D;">"bookMeta"</span>})</span>
<span id="cb7-37">    rating_text <span class="op" style="color: #5E5E5E;">=</span> rating_divs[<span class="dv" style="color: #AD0000;">0</span>].find_all(<span class="st" style="color: #20794D;">"span"</span>, {<span class="st" style="color: #20794D;">"itemprop"</span>: <span class="st" style="color: #20794D;">"ratingValue"</span>})[<span class="dv" style="color: #AD0000;">0</span>].text</span>
<span id="cb7-38">    book_rating.append(rating_text)</span>
<span id="cb7-39">    </span>
<span id="cb7-40">    <span class="co" style="color: #5E5E5E;">#Extracting page particulars</span></span>
<span id="cb7-41">    page_divs <span class="op" style="color: #5E5E5E;">=</span> note_soup.find_all(<span class="st" style="color: #20794D;">"div"</span>, {<span class="st" style="color: #20794D;">"class"</span>: <span class="st" style="color: #20794D;">"row"</span>})</span>
<span id="cb7-42">    <span class="cf" style="color: #003B4F;">try</span>:</span>
<span id="cb7-43">        page_text <span class="op" style="color: #5E5E5E;">=</span> page_divs[<span class="dv" style="color: #AD0000;">0</span>].find_all(<span class="st" style="color: #20794D;">"span"</span>, {<span class="st" style="color: #20794D;">"itemprop"</span>: <span class="st" style="color: #20794D;">"numberOfPages"</span>})[<span class="dv" style="color: #AD0000;">0</span>].text.strip(<span class="st" style="color: #20794D;">'pages'</span>)</span>
<span id="cb7-44">    <span class="cf" style="color: #003B4F;">except</span> <span class="pp" style="color: #AD0000;">IndexError</span>:</span>
<span id="cb7-45">        page_text <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb7-46">    book_pages.append(page_text)</span>
<span id="cb7-47">    </span>
<span id="cb7-48">    <span class="co" style="color: #5E5E5E;">#Extracting description particulars</span></span>
<span id="cb7-49">    description_divs <span class="op" style="color: #5E5E5E;">=</span> note_soup.find_all(<span class="st" style="color: #20794D;">"div"</span>, {<span class="st" style="color: #20794D;">"class"</span>: <span class="st" style="color: #20794D;">"readable stacked"</span>, <span class="st" style="color: #20794D;">"id"</span>: <span class="st" style="color: #20794D;">"description"</span>})</span>
<span id="cb7-50">    <span class="cf" style="color: #003B4F;">try</span>:</span>
<span id="cb7-51">        description_text <span class="op" style="color: #5E5E5E;">=</span> description_divs[<span class="dv" style="color: #AD0000;">0</span>].find_all(<span class="st" style="color: #20794D;">"span"</span>)[<span class="dv" style="color: #AD0000;">1</span>].text</span>
<span id="cb7-52">    <span class="cf" style="color: #003B4F;">except</span> <span class="pp" style="color: #AD0000;">IndexError</span>:</span>
<span id="cb7-53">        <span class="cf" style="color: #003B4F;">try</span>:</span>
<span id="cb7-54">            description_text <span class="op" style="color: #5E5E5E;">=</span> description_divs[<span class="dv" style="color: #AD0000;">0</span>].find_all(<span class="st" style="color: #20794D;">"span"</span>)[<span class="dv" style="color: #AD0000;">0</span>].text</span>
<span id="cb7-55">        <span class="cf" style="color: #003B4F;">except</span> <span class="pp" style="color: #AD0000;">IndexError</span>:</span>
<span id="cb7-56">            description_text <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"Nil"</span></span>
<span id="cb7-57">    book_description.append(description_text)</span>
<span id="cb7-58">        </span>
<span id="cb7-59">    <span class="co" style="color: #5E5E5E;">#Incremeting the loop counter</span></span>
<span id="cb7-60">    i <span class="op" style="color: #5E5E5E;">=</span> i<span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span></span></code></pre></div>
<p>It will take a couple of minutes to scrape through all 50 links. Most of the raw data look messy, and hence require some cleaning up. After some tidying, we can use the <em>pandas</em> package to organise all the data into a data frame (see below).</p>
<p><img src="https://nienxiangtou.com/posts/web-scraping-goodreads/image3.webp" class="img-fluid"></p>
<p>You may also sort the data frame based on its ratings using the <em>sort_values</em> method. That will inform us that the highest rated book is “The Rise of the Ultra Runners: A Journey to the Edge of Human Endurance” by Adharanand Finn with an average 4.45 rating. Finally, we can export all these data into a nice csv file for ease of viewing on Excel, using the <em>to_csv</em> method.</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;"># Export dataframe into csv file</span></span>
<span id="cb8-2">sorted_book_df.to_csv(<span class="st" style="color: #20794D;">"top running books.csv"</span>)</span></code></pre></div>
<p>Hope you enjoy this blog post and full code can be found <a href="https://gist.github.com/nxrunning/c66139ef0dbea01a565e918959622de3"><u>here</u></a>. Similar codes can be used to scrape other book lists on Goodreads. For my running friends, you may check out the final csv file over <a href="https://github.com/nxrunning/codelibrary/blob/nxrunning-webscraping-goodreads/top%20running%20books.csv"><u>here</u></a>.</p>


</section>

 ]]></description>
  <category>Data science</category>
  <guid>https://nienxiangtou.com/posts/web-scraping-goodreads/index.html</guid>
  <pubDate>Thu, 30 Apr 2020 16:00:00 GMT</pubDate>
  <media:content url="https://nienxiangtou.com/posts/web-scraping-goodreads/image.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>Lactate Paradox</title>
  <dc:creator>Nien Xiang Tou</dc:creator>
  <link>https://nienxiangtou.com/posts/lactate-paradox/index.html</link>
  <description><![CDATA[ 



<p>Blood lactate is associated with fatigue during maximal exercise. This post writes about the phenomenon of reduced blood lactate concentration found with increasing altitude.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/lactate-paradox/image.webp" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Mount Everest. Source: Wikipedia</figcaption><p></p>
</figure>
</div>
<p>Energy production during physical work comes from three energy systems: 1) adenosine triphosphate creatine phosphate (ATP-CP), 2) anaerobic glycolysis, and 3) aerobic system. All three systems work concurrently to produce energy, but dominance of any one system is dependent on exercise intensity and duration. Supply of energy for muscle contraction during endurance exercise primarily comes from either aerobic or anaerobic systems. The key difference between the two systems is that aerobic system requires oxygen in the production of energy but anaerobic system does not.</p>
<p>It has been traditionally believed that endurance exercise performance is limited by one’s maximal aerobic capacity (VO2max). Exercising beyond this capacity will shift the energy supply to become more reliant on the anaerobic energy system instead. Consequently, low oxygenation in muscles leads to accumulation of blood lactate, or more commonly known as lactic acid. In a classic <a href="https://physoc.onlinelibrary.wiley.com/doi/abs/10.1113/jphysiol.1907.sp001194"><u>study</u></a>, high levels of blood lactate was found in frog muscles that were stimulated to contract to failure. This has led to the hypothesis that blood lactate is associated with physical fatigue.</p>
<section id="exercising-in-altitude" class="level2">
<h2 class="anchored" data-anchor-id="exercising-in-altitude">Exercising in Altitude</h2>
<p>If you have been in the mountains, you will notice that breathing gets more difficult with advancing altitude levels. Naturally, exercise performance also becomes more exhaustive under such conditions. Since blood lactate is associated with anaerobic energy pathways, higher lactate concentrations are expected at high altitude, whereby oxygen levels are lower. Indeed, this is so among individuals who first experienced altitude. However, peak blood lactate concentration was found to decrease with increasing altitude among individuals who were acclimatised to altitude.</p>
<p>The phenomenon of lower peak blood lactate concentration under greater hypoxic conditions at high altitude levels is puzzling to physiologists. This phenomenon is termed the “lactate paradox”. The paradox was confirmed in <a href="https://journals.physiology.org/doi/abs/10.1152/jappl.1989.66.5.2454"><u>Operation Everest II</u></a>, a study that examined acclimatisation effects of participants at altitude levels equivalent to the summit of Mount Everest, approximately 8848 metres high. It was discovered that the blood lactate concentrations among acclimatised subjects during maximal exercise at high altitude level were not significantly different as compared to during rest at sea levels.</p>
<p>To date, the lactate paradox remains poorly understood. Nevertheless, this phenomenon suggests that blood lactate is not necessarily associated with physical fatigue. Hence, the theoretical belief that endurance exercise performance is limited by accumulation of blood lactate in skeletal muscles is unlikely correct.</p>


</section>

 ]]></description>
  <category>Sport science</category>
  <guid>https://nienxiangtou.com/posts/lactate-paradox/index.html</guid>
  <pubDate>Fri, 24 Apr 2020 16:00:00 GMT</pubDate>
  <media:content url="https://nienxiangtou.com/posts/lactate-paradox/image.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>Animated Data Visualisation of the Covid-19 Pandemic using R</title>
  <dc:creator>Nien Xiang Tou</dc:creator>
  <link>https://nienxiangtou.com/posts/Animated-data-viz-covid19/index.html</link>
  <description><![CDATA[ 



<p>Number of infected cases and deaths around the world continues to rise daily. This article visualises how the pandemic has evolved in certain countries using animated line plots on R.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/Animated-data-viz-covid19/image.webp" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Illustration of the coronavirus particle. Source: Centers for Disease Control and Prevention</figcaption><p></p>
</figure>
</div>
<section id="china-breakout" class="level2">
<h2 class="anchored" data-anchor-id="china-breakout">China Breakout</h2>
<p>Whilethe true origin of the virus remains debatable, the very first reported covid-19 case was detected in Wuhan City, Hubei Province of China. Since then, the numbers have skyrocketed. Using the numbers reported in the daily situation reports by World Health Organization (WHO), let’s visualise how the outbreak has developed since 1st February 2020 using <em>gganimate</em> on R.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/Animated-data-viz-covid19/image2.gif" class="img-fluid figure-img"></p>
</figure>
</div>
<p>The figure above illustrates how the number of cases increased day by day. The exact dates are reflected in the subtitle. Over the period of almost two months, the number of confirmed cases has increased from 11821 to 81601 at the point of writing. From the graph, we can see a sharp increase in cases on 14th February. It can also be seen that the rate of increase seems to decline since March.</p>
</section>
<section id="southeast-asia" class="level2">
<h2 class="anchored" data-anchor-id="southeast-asia">Southeast Asia</h2>
<p>Next, let’s visualise how the virus has developed closer to home. The figure below illustrates the breakout in certain Southeast Asian countries.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/Animated-data-viz-covid19/image3.gif" class="img-fluid figure-img"></p>
</figure>
</div>
<p>At the start of February, Singapore was leading the charts over its neighbours. Things have changed very quickly since early March. The number of reported cases in Malaysia surpassed Singapore on 15th March. Presently, the pandemic is faring much worse in many other Southeast Asian countries as compared to Singapore.</p>
</section>
<section id="rest-of-the-world" class="level2">
<h2 class="anchored" data-anchor-id="rest-of-the-world">Rest of the World</h2>
<p>Covid-19 was announced a pandemic on 11th March 2020 given the alarming levels of the virus outbreak. In such a connected world today, it was hard for any countries to get off the hook. Let’s take a look at some other notable countries being hit.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/Animated-data-viz-covid19/image4.gif" class="img-fluid figure-img"></p>
</figure>
</div>
<p>The graph clearly shows the trajectories of the virus spread differ between countries. For example, there was a sharp increase in number of cases in South Korea during the second half of February. The rate of increase quickly slowed in March. On the other hand, Italy is still facing an exponential manner of spread at the moment. Based on the figures, we can infer the extent of success in countries’ attempt to contain the virus.</p>
<p>Data visualisation code and dataset can be found on my <a href="https://github.com/nxrunning/codelibrary/tree/nxrunning-covid19">github</a>.</p>


</section>

 ]]></description>
  <category>Data visualisation</category>
  <guid>https://nienxiangtou.com/posts/Animated-data-viz-covid19/index.html</guid>
  <pubDate>Mon, 23 Mar 2020 16:00:00 GMT</pubDate>
  <media:content url="https://nienxiangtou.com/posts/Animated-data-viz-covid19/image.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>Web Scraping and Data Visualising with R: EPL 19/20 Goal Stats</title>
  <dc:creator>Nien Xiang Tou</dc:creator>
  <link>https://nienxiangtou.com/posts/web-scraping-and-data-visualising-with-R-EPL19/20-goal-stats/index.html</link>
  <description><![CDATA[ 



<p>Web scraping opens doors to a myriad of data sources online. Be it text or numbers, web scraping allows us to extract online data into spreadsheets in our computer. With reference to code from <a href="http://www.fcrstats.com/dataviz.html"><u>FC RSTATS</u></a>, this article documents a walk through on how to scrape football data from the web and visualising the data using open-source programming platform, R.</p>
<section id="required-libraries" class="level2">
<h2 class="anchored" data-anchor-id="required-libraries">1. Required Libraries</h2>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="fu" style="color: #4758AB;">library</span>(rvest)</span>
<span id="cb1-2"><span class="fu" style="color: #4758AB;">library</span>(ggplot2)</span>
<span id="cb1-3"><span class="fu" style="color: #4758AB;">library</span>(plyr)</span>
<span id="cb1-4"><span class="fu" style="color: #4758AB;">library</span>(ggrepel)</span></code></pre></div>
<p>The above are the required libraries in this walk-through. The two main libraries are <em>rvest</em> and <em>ggplot2,</em> which are used to perform web scraping and plotting graphs respectively.The <em>plyr</em> library helps us in data cleaning while the <em>ggrepel</em> library helps to avoid overlapping of labels in the graphs.</p>
</section>
<section id="webpage" class="level2">
<h2 class="anchored" data-anchor-id="webpage">2. Webpage</h2>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1">url <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="st" style="color: #20794D;">"https://en.wikipedia.org/wiki/2019%E2%80%9320_Premier_League"</span></span></code></pre></div>
<p>In this article, we are scraping data from a Wikipedia page, showing information on the present English Premier League. You may access the page through the url link specified above. Specifically, I am interested in extracting information on the goals scored (GF) and goals conceded (GA) of each team from the table below.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/web-scraping-and-data-visualising-with-R-EPL19/20-goal-stats/image2.webp" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Screenshot of the table in which data would be scraped</figcaption><p></p>
</figure>
</div>
</section>
<section id="scrape-the-data" class="level2">
<h2 class="anchored" data-anchor-id="scrape-the-data">3. Scrape the data</h2>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1">scraped_page <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">read_html</span>(url)</span>
<span id="cb3-2"></span>
<span id="cb3-3"><span class="co" style="color: #5E5E5E;">#Scraping the Team Column</span></span>
<span id="cb3-4">Teams <span class="ot" style="color: #003B4F;">&lt;-</span> scraped_page <span class="sc" style="color: #5E5E5E;">%&gt;%</span>  </span>
<span id="cb3-5">    <span class="fu" style="color: #4758AB;">html_nodes</span>(<span class="st" style="color: #20794D;">"h2+ .wikitable th+ td"</span>) <span class="sc" style="color: #5E5E5E;">%&gt;%</span>  </span>
<span id="cb3-6">    <span class="fu" style="color: #4758AB;">html_text</span>() <span class="sc" style="color: #5E5E5E;">%&gt;%</span>  </span>
<span id="cb3-7">    <span class="fu" style="color: #4758AB;">as.character</span>()</span>
<span id="cb3-8"></span>
<span id="cb3-9"><span class="co" style="color: #5E5E5E;">#Scraping the GF column</span></span>
<span id="cb3-10">Goals_for <span class="ot" style="color: #003B4F;">&lt;-</span> scraped_page <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb3-11">  <span class="fu" style="color: #4758AB;">html_nodes</span>(<span class="st" style="color: #20794D;">"h2+ .wikitable td:nth-child(7) , th:nth-child(7) abbr"</span>) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb3-12">  <span class="fu" style="color: #4758AB;">html_text</span>() <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb3-13">  as.numeric</span>
<span id="cb3-14"></span>
<span id="cb3-15"><span class="co" style="color: #5E5E5E;">#Scraping the GA column</span></span>
<span id="cb3-16">Goals_against<span class="ot" style="color: #003B4F;">&lt;-</span> scraped_page <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb3-17">  <span class="fu" style="color: #4758AB;">html_nodes</span>(<span class="st" style="color: #20794D;">"h2+ .wikitable td:nth-child(8)"</span>) <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb3-18">  <span class="fu" style="color: #4758AB;">html_text</span>() <span class="sc" style="color: #5E5E5E;">%&gt;%</span></span>
<span id="cb3-19">  as.numeric</span></code></pre></div>
<p>First, we read the web page and save the data to the variable named <em>scraped_page</em>. Based on the above table, we are interested in three columns: Team, GF and GA. Each column is scraped separately and saved to a variable name (i.e.&nbsp;Teams, Goals_for, Goals_against). The codes look identical to one another since we are just repeating the scraping process. The difference is to specify the location of the data to be scraped. The respective locations for each location are specified in red above. For example, “h2+ .wikitable th+ td” tells the code to locate the team column in the scraped page. Each location can be easily found through the use of <a href="https://selectorgadget.com/"><u>SelectorGadget</u></a>. Click the link to see more details.</p>
</section>
<section id="cleaning-the-data" class="level2">
<h2 class="anchored" data-anchor-id="cleaning-the-data">4. Cleaning the data</h2>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><span class="co" style="color: #5E5E5E;">#Removing "\n" in the teams </span></span>
<span id="cb4-2">Teams <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">gsub</span>(<span class="st" style="color: #20794D;">"</span><span class="sc" style="color: #5E5E5E;">\n</span><span class="st" style="color: #20794D;">"</span>,<span class="st" style="color: #20794D;">""</span>,Teams)</span>
<span id="cb4-3"></span>
<span id="cb4-4"><span class="co" style="color: #5E5E5E;">#Remove NA case</span></span>
<span id="cb4-5">Goals_for <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">na.omit</span>(Goals_for)</span>
<span id="cb4-6"></span>
<span id="cb4-7"><span class="co" style="color: #5E5E5E;">#Combining all scraped data into a dataframe</span></span>
<span id="cb4-8">df <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">data.frame</span>(Teams, Goals_for, Goals_against)</span>
<span id="cb4-9"></span>
<span id="cb4-10"><span class="co" style="color: #5E5E5E;">#Renaming the values of Liverpool and Manchester City </span></span>
<span id="cb4-11">df<span class="sc" style="color: #5E5E5E;">$</span>Teams <span class="ot" style="color: #003B4F;">&lt;-</span> <span class="fu" style="color: #4758AB;">mapvalues</span>(df<span class="sc" style="color: #5E5E5E;">$</span>Teams, <span class="at" style="color: #657422;">from=</span><span class="fu" style="color: #4758AB;">c</span>(<span class="st" style="color: #20794D;">"Liverpool (Q)"</span>,<span class="st" style="color: #20794D;">"Manchester City[a]"</span>), <span class="at" style="color: #657422;">to=</span><span class="fu" style="color: #4758AB;">c</span>(<span class="st" style="color: #20794D;">"Liverpool"</span>, <span class="st" style="color: #20794D;">"Manchester City"</span>))</span></code></pre></div>
<p>If you preview each of the variable, you will find some slight discrepancies. For example, many of the teams have a ‘\n’ in their names. Hence, the above code helps to clean the data and combines them into a nice spreadsheet below.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/web-scraping-and-data-visualising-with-R-EPL19/20-goal-stats/Image3.jpg" class="img-fluid figure-img"></p>
</figure>
</div>
</section>
<section id="data-visualisation" class="level2">
<h2 class="anchored" data-anchor-id="data-visualisation">5. Data Visualisation</h2>
<p>Following the code from <a href="http://www.fcrstats.com/dataviz.html">FC RSTATS</a>, we can create a scatter plot as below. Each point represents each team in the league. The x and y axes represent the goals scored and goals conceded respectively. The plot is divided into quadrants by the two dotted lines. The horizontal dotted line represents the average goals conceded while the vertical horizontal dotted line represents the average goals scored.</p>
<p>Based on this simple graph, we can see that the teams located on the bottom right are the better performing teams with both strong attack and defence. Conversely, the teams in the top left quadrant have the worst performance.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/web-scraping-and-data-visualising-with-R-EPL19/20-goal-stats/image4.webp" class="img-fluid figure-img"></p>
</figure>
</div>
</section>
<section id="dividing-teams-into-four-clusters" class="level2">
<h2 class="anchored" data-anchor-id="dividing-teams-into-four-clusters">6. Dividing teams into four clusters</h2>
<p>To better visualise the separation in performance, we can represent each quadrant in different colours. First, we create a new column in the spreadsheet and name it cluster. The code below will separate each team into their respective clusters based on their goal stats.</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><span class="co" style="color: #5E5E5E;">#Creating a cluster column</span></span>
<span id="cb5-2">df<span class="sc" style="color: #5E5E5E;">$</span>Cluster <span class="ot" style="color: #003B4F;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb5-3"></span>
<span id="cb5-4"><span class="co" style="color: #5E5E5E;">#Using for loop and ifelse statements to create different clusters </span></span>
<span id="cb5-5"><span class="cf" style="color: #003B4F;">for</span>(i <span class="cf" style="color: #003B4F;">in</span> <span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">:</span> <span class="fu" style="color: #4758AB;">nrow</span>(df)) {</span>
<span id="cb5-6">  <span class="cf" style="color: #003B4F;">if</span> (df<span class="sc" style="color: #5E5E5E;">$</span>Goals_for[i] <span class="sc" style="color: #5E5E5E;">&gt;</span> <span class="fu" style="color: #4758AB;">mean</span>(df<span class="sc" style="color: #5E5E5E;">$</span>Goals_for) <span class="sc" style="color: #5E5E5E;">&amp;</span> df<span class="sc" style="color: #5E5E5E;">$</span>Goals_against[i] <span class="sc" style="color: #5E5E5E;">&lt;</span> <span class="fu" style="color: #4758AB;">mean</span>(df<span class="sc" style="color: #5E5E5E;">$</span>Goals_against)) {</span>
<span id="cb5-7">    df<span class="sc" style="color: #5E5E5E;">$</span>Cluster[i] <span class="ot" style="color: #003B4F;">=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb5-8">  } <span class="cf" style="color: #003B4F;">else</span> <span class="cf" style="color: #003B4F;">if</span> (df<span class="sc" style="color: #5E5E5E;">$</span>Goals_for[i] <span class="sc" style="color: #5E5E5E;">&lt;</span> <span class="fu" style="color: #4758AB;">mean</span>(df<span class="sc" style="color: #5E5E5E;">$</span>Goals_for) <span class="sc" style="color: #5E5E5E;">&amp;</span> df<span class="sc" style="color: #5E5E5E;">$</span>Goals_against[i] <span class="sc" style="color: #5E5E5E;">&lt;</span> <span class="fu" style="color: #4758AB;">mean</span>(df<span class="sc" style="color: #5E5E5E;">$</span>Goals_against)) {</span>
<span id="cb5-9">    df<span class="sc" style="color: #5E5E5E;">$</span>Cluster[i] <span class="ot" style="color: #003B4F;">=</span> <span class="dv" style="color: #AD0000;">2</span> </span>
<span id="cb5-10">  } <span class="cf" style="color: #003B4F;">else</span> <span class="cf" style="color: #003B4F;">if</span> (df<span class="sc" style="color: #5E5E5E;">$</span>Goals_for[i] <span class="sc" style="color: #5E5E5E;">&gt;</span> <span class="fu" style="color: #4758AB;">mean</span>(df<span class="sc" style="color: #5E5E5E;">$</span>Goals_for) <span class="sc" style="color: #5E5E5E;">&amp;</span> df<span class="sc" style="color: #5E5E5E;">$</span>Goals_against[i] <span class="sc" style="color: #5E5E5E;">&gt;</span> <span class="fu" style="color: #4758AB;">mean</span>(df<span class="sc" style="color: #5E5E5E;">$</span>Goals_against)) {</span>
<span id="cb5-11">    df<span class="sc" style="color: #5E5E5E;">$</span>Cluster[i] <span class="ot" style="color: #003B4F;">=</span> <span class="dv" style="color: #AD0000;">3</span></span>
<span id="cb5-12">  } <span class="cf" style="color: #003B4F;">else</span> {</span>
<span id="cb5-13">    df<span class="sc" style="color: #5E5E5E;">$</span>Cluster[i] <span class="ot" style="color: #003B4F;">=</span> <span class="dv" style="color: #AD0000;">4</span></span>
<span id="cb5-14">  }</span>
<span id="cb5-15">}</span>
<span id="cb5-16"></span>
<span id="cb5-17"><span class="co" style="color: #5E5E5E;">#Making the cluster columns a factor</span></span>
<span id="cb5-18">df<span class="sc" style="color: #5E5E5E;">$</span>Cluster <span class="ot" style="color: #003B4F;">=</span> <span class="fu" style="color: #4758AB;">factor</span>(df<span class="sc" style="color: #5E5E5E;">$</span>Cluster, <span class="at" style="color: #657422;">levels =</span> <span class="fu" style="color: #4758AB;">c</span>(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">4</span>), </span>
<span id="cb5-19">                    <span class="at" style="color: #657422;">labels =</span> </span>
<span id="cb5-20">                    <span class="fu" style="color: #4758AB;">c</span>(<span class="st" style="color: #20794D;">"Strong attack</span><span class="sc" style="color: #5E5E5E;">\n</span><span class="st" style="color: #20794D;">Strong defence"</span>,</span>
<span id="cb5-21">                    <span class="st" style="color: #20794D;">"Poor attack</span><span class="sc" style="color: #5E5E5E;">\n</span><span class="st" style="color: #20794D;">Strong defence"</span>,</span>
<span id="cb5-22">                    <span class="st" style="color: #20794D;">"Strong attack</span><span class="sc" style="color: #5E5E5E;">\n</span><span class="st" style="color: #20794D;">Poor defence"</span>,</span>
<span id="cb5-23">                    <span class="st" style="color: #20794D;">"Poor attack</span><span class="sc" style="color: #5E5E5E;">\n</span><span class="st" style="color: #20794D;">Poor defence"</span>))</span>
<span id="cb5-24">                    </span></code></pre></div>
<p>Next, we will use the ggplot2 library to visualise our data. The comments in green help to explain each respective line of code.</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><span class="co" style="color: #5E5E5E;">#Specifying the variables and using colours to represent each cluster</span></span>
<span id="cb6-2"><span class="fu" style="color: #4758AB;">ggplot</span>(df, <span class="fu" style="color: #4758AB;">aes</span>(<span class="at" style="color: #657422;">x =</span> Goals_for, <span class="at" style="color: #657422;">y =</span> Goals_against, <span class="at" style="color: #657422;">label =</span> Teams, <span class="at" style="color: #657422;">colour =</span> Cluster))<span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb6-3">  <span class="co" style="color: #5E5E5E;">#Plotting each team on the graph using a geometric point</span></span>
<span id="cb6-4">  <span class="fu" style="color: #4758AB;">geom_point</span>()<span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb6-5">  <span class="co" style="color: #5E5E5E;">#Plotting the vertical dotted line to represent the average goals scored</span></span>
<span id="cb6-6">  <span class="fu" style="color: #4758AB;">geom_vline</span>(<span class="at" style="color: #657422;">xintercept=</span><span class="fu" style="color: #4758AB;">mean</span>(Goals_for), <span class="at" style="color: #657422;">linetype=</span><span class="st" style="color: #20794D;">"dashed"</span>, </span>
<span id="cb6-7">  <span class="at" style="color: #657422;">alpha =</span> <span class="fl" style="color: #AD0000;">0.4</span>, <span class="at" style="color: #657422;">colour =</span> <span class="st" style="color: #20794D;">"red"</span>) <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb6-8">  <span class="co" style="color: #5E5E5E;">#Plotting the horizontal dotted line to represent the average goals conceded</span></span>
<span id="cb6-9">  <span class="fu" style="color: #4758AB;">geom_hline</span>(<span class="at" style="color: #657422;">yintercept=</span><span class="fu" style="color: #4758AB;">mean</span>(Goals_against), <span class="at" style="color: #657422;">linetype=</span><span class="st" style="color: #20794D;">"dashed"</span>, </span>
<span id="cb6-10">  <span class="at" style="color: #657422;">alpha =</span> <span class="fl" style="color: #AD0000;">0.4</span>, <span class="at" style="color: #657422;">colour =</span> <span class="st" style="color: #20794D;">"red"</span>) <span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb6-11">  <span class="co" style="color: #5E5E5E;">#Geom_text_repel helps to avoid overlapping of labels in the points</span></span>
<span id="cb6-12">  <span class="fu" style="color: #4758AB;">geom_text_repel</span>(<span class="fu" style="color: #4758AB;">aes</span>(Goals_for, Goals_against, <span class="at" style="color: #657422;">label =</span> Teams), </span>
<span id="cb6-13">                  <span class="at" style="color: #657422;">size =</span> <span class="dv" style="color: #AD0000;">2</span>, <span class="at" style="color: #657422;">colour =</span> <span class="st" style="color: #20794D;">"black"</span>, <span class="at" style="color: #657422;">fontface =</span> <span class="st" style="color: #20794D;">"bold"</span>)<span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb6-14">  <span class="co" style="color: #5E5E5E;">#Labelling of axes and title</span></span>
<span id="cb6-15">  <span class="fu" style="color: #4758AB;">labs</span>(<span class="at" style="color: #657422;">title =</span> <span class="st" style="color: #20794D;">"EPL 2019/2020: Goals For vs Goals Against"</span>,</span>
<span id="cb6-16">       <span class="at" style="color: #657422;">x =</span> <span class="st" style="color: #20794D;">"Goals For"</span>, <span class="at" style="color: #657422;">y =</span> <span class="st" style="color: #20794D;">"Goals Against"</span>,</span>
<span id="cb6-17">       <span class="at" style="color: #657422;">colour =</span> <span class="st" style="color: #20794D;">" "</span>)<span class="sc" style="color: #5E5E5E;">+</span></span>
<span id="cb6-18">  <span class="co" style="color: #5E5E5E;">#Specifying position of the legend</span></span>
<span id="cb6-19">  <span class="fu" style="color: #4758AB;">theme</span>(<span class="at" style="color: #657422;">legend.position =</span> <span class="st" style="color: #20794D;">"top"</span>)</span>
<span id="cb6-20"></span>
<span id="cb6-21"><span class="co" style="color: #5E5E5E;">#Save the plot in your working directory</span></span>
<span id="cb6-22"><span class="fu" style="color: #4758AB;">ggsave</span>(<span class="st" style="color: #20794D;">"output.jpeg"</span>, <span class="at" style="color: #657422;">dpi =</span> <span class="dv" style="color: #AD0000;">300</span>)</span>
<span id="cb6-23">                    </span></code></pre></div>
<p>The resulting plot is below.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/web-scraping-and-data-visualising-with-R-EPL19/20-goal-stats/image5.webp" class="img-fluid figure-img"></p>
</figure>
</div>
<p>Full code for this article can be accessed through my <a href="https://gist.github.com/nxrunning/1d00a5b5633f669deb5c2443f36cb17a"><u>github</u></a>.</p>
<p>PS: If you actually count the number of points on the plot, there are only 19 instead of 20. This is because Newcastle and Watford happen to have exactly the same goal stats at the time of writing.</p>


</section>

 ]]></description>
  <category>Data science</category>
  <category>Football</category>
  <guid>https://nienxiangtou.com/posts/web-scraping-and-data-visualising-with-R-EPL19/20-goal-stats/index.html</guid>
  <pubDate>Wed, 19 Feb 2020 16:00:00 GMT</pubDate>
  <media:content url="https://nienxiangtou.com/posts/web-scraping-and-data-visualising-with-R-EPL19/20-goal-stats/image.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>Is the English Premier League getting more competitive?</title>
  <dc:creator>Nien Xiang Tou</dc:creator>
  <link>https://nienxiangtou.com/posts/Is-the-EPL-getting-more-competitive/index.html</link>
  <description><![CDATA[ 



<p>Is the English Premier League more or less competitive as compared to a decade ago? This article examines and compares the competitiveness of different seasons based on the coefficient of variation metric.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/Is-the-EPL-getting-more-competitive/image.webp" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">The “Invincible” Arsenal lifting the EPL trophy in 2003/2004. Source: Goal.com</figcaption><p></p>
</figure>
</div>
<p>Presently, Liverpool is en route to being runaway champions in the English Premier League (EPL), with 22 points separating them from second-placed Manchester City. Incredibly, the premier league leaders have gone a total of 42 games unbeaten at the moment, with their last defeat happening at the Ethihad Stadium on 3rd January 2019.</p>
<p>Inevitably, this invites a comparison between Liverpool and the “Invincible” Arsenal team. The latter currently holds the record for the longest unbeaten EPL run with 49 games in 2003/2004. To date, the record has stood for close to 16 years. Can Liverpool surpass this incredible record? In an <a href="https://www.goal.com/en/news/liverpool-will-win-title-unbeaten-but-arsenal-invincibles-had-it-/1tvmznt3bdvg91m550qg48m991">online article</a>, former Arsenal player Robert Pires commented that if Liverpool goes on to break the record, the league was much harder in the past as compared to present.</p>
<blockquote class="blockquote">
<p>“They will be champions by going unbeaten, but they can also beat our record. Everything has changed today. People will compare, but I think it was much, much harder in our time.”</p>
</blockquote>
<p>Is he right to say that? This article examines whether the present EPL is indeed getting easier as compared to many years ago. First, let’s visualise how many points were required to become champions across the different past seasons since 2000/2001.</p>
<p><img src="https://nienxiangtou.com/posts/Is-the-EPL-getting-more-competitive/Image2.webp" class="img-fluid"></p>
<p>Based on the figure, we can clearly see that teams need at least 80 points to win the titles. The “Invincible” Arsenal team achieved a total of 90 points in 2003/2004 to lift the championship trophy. However, it is interesting to point out that 90 points would be insufficient to win the league over the past three seasons. Liverpool fans would be especially frustrated that despite accumulating 97 points in 2018/2019 season, they were still that tiny bit shy of the title. Hence, is the league really becoming less competitive like what Robert Pires said?</p>
<section id="coefficient-of-variation" class="level2">
<h2 class="anchored" data-anchor-id="coefficient-of-variation">Coefficient of variation</h2>
<p>With the aim to evaluate the competitiveness of the league, we will use the coefficient of variation (CV) metric. CV is calculated by dividing the standard deviation of a dataset by its mean. It simply represents the relative spread/variance of the data, and ranges between 0 to 1. In finance, CV is used to assess the volatility of stocks. In this article’s context, we compare the competitiveness of different EPL seasons based on each season’s CV. If a league is more competitive, we will expect that the point total of teams to be closer to one another, hence a lower CV. On the other hand, a higher CV represents less competitiveness as there is greater spread in point total among teams.</p>
<p><img src="https://nienxiangtou.com/posts/Is-the-EPL-getting-more-competitive/Image3.webp" class="img-fluid"></p>
<p>The figure above illustrates the CV across different seasons. Generally, we see there’s relatively greater variation in more recent seasons as compared to the past. For example, there’s 29% variation in 2003/2004 season as compared to 39% variation in 2018/2019. Based on the graph, the most competitive season was probably in 2010/2011 with the least variation of 25%. This suggests that there’s some truth in Robert Pires’s comments.</p>
<p><img src="https://nienxiangtou.com/posts/Is-the-EPL-getting-more-competitive/Image4.webp" class="img-fluid"></p>
<p>Next, let’s further analyse the competitiveness of the league based on different standings of the table. The figure above illustrates the CV of the top six teams across different seasons. This tells a slightly different story as compared to the previous graph. The higher CVs were observed in 2003/2004 and 2004/2005 seasons, which suggests greater dispersion in point total among the top teams. This implies relatively less of a close battle for the title in these two seasons. In contrast, we see a clear trend of decreasing CV from season 2005/2006 onwards till about 2015/2016. This coincides with the shift of the traditional “Top Four” (Arsenal, Manchester United, Chelsea, Liverpool) dominance to the emergence of the “Big Six” with Tottenham Hotspur and Manchester City joining in to challenge for the title.</p>
<p>Although there’s an increase in CV among the top six teams in recent seasons, it is still comparatively less than the “Invincible” season. This suggests that it is much more competitive among the top teams in recent seasons as compared to the past. This also indicates that challenging for a champions league qualifying spot is much tougher now than two decades ago.</p>
<p>In conclusion, while the league may be more competitive overall in the past, there is less competition among the top teams when comes to challenging for the title or qualifying for the champions league as compared to present seasons.</p>
<p>Do you agree with Robert Pires’s comments?</p>


</section>

 ]]></description>
  <category>Data science</category>
  <category>Football</category>
  <guid>https://nienxiangtou.com/posts/Is-the-EPL-getting-more-competitive/index.html</guid>
  <pubDate>Sat, 08 Feb 2020 16:00:00 GMT</pubDate>
  <media:content url="https://nienxiangtou.com/posts/Is-the-EPL-getting-more-competitive/image.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>Can possession predict wins in football?</title>
  <dc:creator>Nien Xiang Tou</dc:creator>
  <link>https://nienxiangtou.com/posts/Can-possession-predict-wins-in-football/index.html</link>
  <description><![CDATA[ 



<p>Ball possession is an important performance indicator in football. This article explores the use of logistic regression model to examine a binary classification problem: whether ball possession predicts match win or not.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/Can-possession-predict-wins-in-football/image.webp" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Liverpool’s Salah fending off Manchester City’s Gündoğan for the ball. Source: talksport</figcaption><p></p>
</figure>
</div>
<p>Ball possession in football is seen as an imperative aspect of the game. Many successful teams are often characterised by dominating long periods of possession. The first team that sprints to your mind with such nature of play is likely the Spanish giants, Barcelona. They are often defined by their “tiki-taka” style of play, which constitutes short passing and movement to maintain possession.</p>
<p>Past research have claimed that possession is a critical performance indicator that can differentiate successful teams. Better performing teams tend to maintain significantly longer possession as compared to the less successful teams. In the context of football, it does not matter if you can possess the ball for extended periods but failing to win the match. This leads to an important question, can possession predict wins in football?</p>
<p>In view of the imminent English Premier League (EPL) season, let’s revisit last EPL season’s data to answer this question! The data set consists of all results from the total 380 matches played throughout the season. Each row represents the match statistics of a team in a given match. You may see a preview of the data below.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/Can-possession-predict-wins-in-football/image2.webp" class="img-fluid figure-img" width="584"></p>
<p></p><figcaption class="figure-caption">Data from EPL 18/19 season. Note - Fixture: 1 denotes match day 1, a total of 38 fixtures. Possession: %. Win: 1 denotes a win, 0 denotes otherwise (draw or loss). GS: Goals scored. GA: Goals against. Home/Away: 1 denotes home team, 0 denotes away team.</figcaption><p></p>
</figure>
</div>
<section id="do-better-teams-have-greater-possession" class="level2">
<h2 class="anchored" data-anchor-id="do-better-teams-have-greater-possession">Do better teams have greater possession?</h2>
<p>As mentioned above, it has been claimed that ball possession is a performance indicator that can distinguish the more successful teams. Firstly, let’s visualise the possession of each team ranked by their ball possession!</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/Can-possession-predict-wins-in-football/image3.webp" class="img-fluid figure-img"></p>
</figure>
</div>
<p>No surprise that the EPL champions, Manchester City, with the most points tallied also had the most dominating ball possession among all the teams. From the graph, we can see that there is some truth to the claim, with the “top six” teams all ahead in the ball possession rankings as compared to the rest of the league. The highest ball possession recorded was a whopping 82% by Manchester City during match day 29 away to Bournemouth. However, the score did not truly reflect such one-sided dominance, with City edging Bournemouth by just a goal.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/Can-possession-predict-wins-in-football/image4.webp" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Each data point represents the possession and match outcome of a team. 1 denotes a match win, while 0 denotes otherwise (draw or loss).</figcaption><p></p>
</figure>
</div>
</section>
<section id="does-ball-possession-translate-into-results" class="level2">
<h2 class="anchored" data-anchor-id="does-ball-possession-translate-into-results">Does ball possession translate into results?</h2>
<p>In the data visualization above, we can see that all results are classified into either wins or otherwise (draw or loss). With so much emphasis on ball possession in today’s football, this scatter plot seems to tell us otherwise, with no clear threshold of possession level that guarantees a win. We can see that a winning team can have close to 20% of possession while a non-winning team can have close to 80% of possession. For example, Crystal Palace pulled off a surprising win (3-2) against Manchester City at the Etihad Stadium on match day 18, with only 21% of ball possession during the match. Therefore, is ball possession a reliable predictor of match wins?</p>
</section>
<section id="logistic-regression" class="level2">
<h2 class="anchored" data-anchor-id="logistic-regression"><strong>Logistic Regression</strong></h2>
<p>This is a classification problem, as we use possession as an independent variable to predict the match result. The problem is simplified to be a binary classification scenario, whereby the result can only have two outcomes: either win or otherwise (i.e.&nbsp;draw or loss). Since the dependent variable is categorical in nature, logistic regression is employed to help us answer our question. In this example, we make use of the StatsModel module, which is an open-sourced Python module encompassing several statistical functions. You may see the summary of the logistic regressions result below.</p>
<p><span style="text-align: center"><img src="https://nienxiangtou.com/posts/Can-possession-predict-wins-in-football/image5.webp" class="img-fluid" style="text-align: center"></span><br>
</p>
<p>The results showed that ball possession is a significant predictor of match wins. This suggests that possession is indeed a meaningful indicator of a match outcome. The coefficient of the possession variable is 0.0335, and this implies that when ball possession level increases by 1%, the odds of winning the match increase by 3.41%. Greater ball possession could translate to more creation of goal-scoring opportunities. Possessing the ball more also means reducing opponent’s chances of scoring since a team will need to have the ball first before they can even try to score. Such situations could contribute to a greater likelihood of winning the match.</p>
</section>
<section id="how-accurate-is-this-model" class="level2">
<h2 class="anchored" data-anchor-id="how-accurate-is-this-model"><strong>How accurate is this model?</strong></h2>
<p>In this example, the logistic regression model was trained with the data from all matches in EPL season 18/19. We could deploy the model to predict a match outcome given an input amount of possession levels. The model predicts by calculating the probability of either outcomes (value between 0 and 1). In this example, if a given possession level has a probability of winning greater than 0.5, it will be predicted that the team wins the match and vice versa.</p>
<p>In the field of machine learning and data science, the accuracy rate of a classification model can often be interpreted through a <em>confusion matrix</em>. A confusion matrix is a simple table that shows the accuracy of the model by comparing the predicted values with the actual values in the data set. You may see the confusion matrix for this example below.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/Can-possession-predict-wins-in-football/image6.webp" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Confusion matrix of logistic regression model. Note- 1 denotes win, 0 denotes otherwise (draw or loss).</figcaption><p></p>
</figure>
</div>
<p>The confusion matrix compares all 760 predicted outcomes with the actual recorded outcomes. From the matrix, we can see that 372 cases were correctly predicted to be non-wins, also termed the <em>true negatives</em>. 204 cases were incorrectly predicted to be non-wins when they actually produced match wins in reality. Such cases are termed <em>false negatives</em>. 79 cases were also incorrectly predicted to be winning outcomes when they were actually non-wins, also known as the <em>false positives</em>. Lastly, 105 cases were correctly predicted to be classified as match wins, which are regarded as the <em>true positives</em>.</p>
<div style="text-align: center">
<p>Accuracy rate = (372+105)/760 * 100</p>
</div>
<p>This model was found to be 62.76% accurate! I will leave it to your personal judgement whether this model is acceptable. Obviously, football is a game with so many variables that can influence the outcome of a match. Therefore, it is not surprising to expect such accuracy of a simple model with a single predictor variable. Nevertheless, this post showcases that ball possession is a significant variable that can help us predict match outcomes. However, possession itself does not tell the full story.</p>


</section>

 ]]></description>
  <category>Data science</category>
  <category>Football</category>
  <guid>https://nienxiangtou.com/posts/Can-possession-predict-wins-in-football/index.html</guid>
  <pubDate>Wed, 07 Aug 2019 16:00:00 GMT</pubDate>
  <media:content url="https://nienxiangtou.com/posts/Can-possession-predict-wins-in-football/image.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>Your perception is your reality</title>
  <dc:creator>Nien Xiang Tou</dc:creator>
  <link>https://nienxiangtou.com/posts/Your-perception-is-your-reality/index.html</link>
  <description><![CDATA[ 



<p>We experience a wide range of sensations during exercise. This article highlights the importance of studying perception, especially in the context of regulation of exercise.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://nienxiangtou.com/posts/Your-perception-is-your-reality/image.webp" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Kenya’s Lawrence Cherono battling with Ethopia’s Lelisa Desisa in the 2019 Boston Marathon. Source: Winslow Townson/Associated Press</figcaption><p></p>
</figure>
</div>
<p>Have you ever stood at the end of a marathon, and witnessed how many people sprinted across the finish line? How is it possible for somebody who slowed down or was walking halfway through the race and yet managed to run the fastest right at the end of the race?</p>
<p>This is the end-spurt phenomenon commonly seen in endurance events among elites as well as the recreational athletes. Such phenomenon challenges the concept of fatigue, and this was exactly what sparked my interest in pursuing my PhD study that aims to better understand individual’s perceptual responses in self-regulation of exercise.</p>
<p>Traditionally, it has been thought that fatigue stems from your physiological limits. From such a perspective, why somebody slows down during a race is completely due to physiological reasons such as depletion of muscle glycogen, lactate, environmental stress or the inability of your heart to supply enough oxygen to the muscles. As a result, the athlete is unable to recruit more muscle fibers to meet the exercise demands and hence slowing down. However, if such hypothesis is true, it is not possible for the athlete to speed up at the end of the race when he or she is supposed to feel the most exhausted.</p>
<section id="the-central-governor" class="level2">
<h2 class="anchored" data-anchor-id="the-central-governor">The Central Governor</h2>
<p>This paradox was first challenged by famous South African sport scientist, Professor Tim Noakes, who also authored the running bible, <em>Lore of Running</em>. In 1996, he delivered the prestigious J. B. Wolffe Memorial Lecture at the American College of Sports Medicine (ACSM) conference. He pointed out that most people did not die running a marathon, which meant they could have ran faster during the race. Therefore, the traditional physiological model was flawed. He later went on to publish a new theoretical model to explain regulation of exercise performance, termed the “Central Governor”, which remains a hot debating topic in the sports science domain to date.</p>
<p>This model postulates that exercise performance is regulated by a centralized control center, the brain. Exercise performance is regulated in a manner based on constant feedback between the body and the brain. As we push the limits of our body, the brain generates a whole range of sensations consciously felt by us. The sensations felt during exercise are not the consequences of fatigue, but a protective mechanism to ensure that we complete our exercise in a safe manner. In short, the brain stops us from exercising to the point that we kill ourselves.</p>
</section>
<section id="why-study-perception" class="level2">
<h2 class="anchored" data-anchor-id="why-study-perception">Why study perception?</h2>
<p>It is important to understand that in the context of an endurance event such as a marathon, athletes regulate their exercise performance in an anticipatory manner. This means individuals including novice runners naturally try to pace themselves in a sustainable manner to complete the race. Research have empirically shown that athletes slow down way before they reach the critical core temperature, and before the glycogen tank completely empties. Regulation of exercise is based on the perceived sensations during exercise, which help to provide feedback on finding the balance between safety and performance.</p>
<p>Why is there a need to study perceptual responses in sports given the tools to monitor a myriad of objective physiological measures such as heart rate, oxygen consumption and blood lactate? This is because when you think you have reached your point of exhaustion during exercise, the truth is you didn’t.</p>
<blockquote class="blockquote">
<p><strong>It is a perceived failure, and not a true failure.</strong></p>
</blockquote>
<p>It is quite impossible to run yourself to true failure in the context of exercise performance. Your true performance probably only happens when you face a life-and-death situation, such as being chased by a lion. This differentiation between a perceived and true failure is very important, as perceptual responses can be influenced by many other factors besides physiological variables.</p>
<p>This is the reason why placebo and psychological effects can affect performance. These effects alter your perceptual responses, and hence your performance. In the words of an Italian sport physiologist, Professor Samuele Marcora, effort perception is claimed to be the “cardinal exercise stopper”. Therefore, whatever factors that can influence your perception can ultimately influence your exercise performance.</p>
<p>Your perception is in fact your reality.</p>


</section>

 ]]></description>
  <category>Sport science</category>
  <guid>https://nienxiangtou.com/posts/Your-perception-is-your-reality/index.html</guid>
  <pubDate>Fri, 02 Aug 2019 16:00:00 GMT</pubDate>
  <media:content url="https://nienxiangtou.com/posts/Your-perception-is-your-reality/image.webp" medium="image" type="image/webp"/>
</item>
<item>
  <title>{B4F502887207:/Publications.html}</title>
  <link>https://nienxiangtou.com/Publications.html</link>
  <description>{B4F502887207:/Publications.html}</description>
  <guid>https://nienxiangtou.com/Publications.html</guid>
  <pubDate>Wed, 12 Oct 2022 03:31:22 GMT</pubDate>
</item>
<item>
  <title>Blog</title>
  <link>https://nienxiangtou.com/blog.html</link>
  <description><![CDATA[ 







<div class="quarto-listing quarto-listing-container-grid" id="listing-listing">
<div class="list grid quarto-listing-cols-3">
<div class="g-col-1" data-index="0" data-categories="Statistics" data-listing-date-sort="1649952000000" data-listing-file-modified-sort="1664955501195" data-listing-reading-time-sort="10.45">
<a href="./posts/Bayesian-vs-Frequentist-Monty-Hall/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://nienxiangtou.com/posts/Bayesian-vs-Frequentist-Monty-Hall/image.webp" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Bayesian versus Frequentist solutions to the Monty Hall Problem
</h5>
<div class="listing-categories">
<div class="listing-category" onclick="window.quartoListingCategory('Statistics'); return false;">
Statistics
</div>
</div>
<div class="card-text listing-description">
This post presents the use of both bayesian and frequentist approaches to solve the famous Monty Hall problem.
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Nien Xiang Tou
</div>
<div class="listing-date">
Apr 15, 2022
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="1" data-categories="Sport science" data-listing-date-sort="1628438400000" data-listing-file-modified-sort="1665372059140" data-listing-reading-time-sort="17.275">
<a href="./posts/Tokyo-olympics-1500m-analysis/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://nienxiangtou.com/posts/Tokyo-olympics-1500m-analysis/image.webp" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Tokyo Olympics: Analysis of the 1500m Event’s Pacing Strategy using the Concept of Critical Speed
</h5>
<div class="listing-categories">
<div class="listing-category" onclick="window.quartoListingCategory('Sport science'); return false;">
Sport science
</div>
</div>
<div class="card-text listing-description">
This post employs the concept of critical spped to analyse the pacing strategy in the 1500m event finals at the Tokyo Olympics.
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Nien Xiang Tou
</div>
<div class="listing-date">
Aug 9, 2021
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="2" data-categories="Statistics" data-listing-date-sort="1614787200000" data-listing-file-modified-sort="1664950781773" data-listing-reading-time-sort="6.98">
<a href="./posts/All-about-that-bayes/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://nienxiangtou.com/posts/All-about-that-bayes/image.webp" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
All about that Bayes: Why individuals appraise similar evidence differently?
</h5>
<div class="listing-categories">
<div class="listing-category" onclick="window.quartoListingCategory('Statistics'); return false;">
Statistics
</div>
</div>
<div class="card-text listing-description">
This post presents how Bayesian inference explains why different individuals appraise similar evidence differently.
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Nien Xiang Tou
</div>
<div class="listing-date">
Mar 4, 2021
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="3" data-categories="Data visualisation,Football" data-listing-date-sort="1606579200000" data-listing-file-modified-sort="1664949886386" data-listing-reading-time-sort="4.88">
<a href="./posts/Radar-charts-football-visualisation/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://nienxiangtou.com/posts/Radar-charts-football-visualisation/image.jpg" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Radar charts in R: Visualising playing styles of EPL football teams
</h5>
<div class="listing-categories">
<div class="listing-category" onclick="window.quartoListingCategory('Data visualisation'); return false;">
Data visualisation
</div>
<div class="listing-category" onclick="window.quartoListingCategory('Football'); return false;">
Football
</div>
</div>
<div class="card-text listing-description">
This post visualises the playing styles of English Premier League football teams with the use of radar charts.
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Nien Xiang Tou
</div>
<div class="listing-date">
Nov 29, 2020
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="4" data-categories="Sport science" data-listing-date-sort="1595952000000" data-listing-file-modified-sort="1664941720364" data-listing-reading-time-sort="5.465">
<a href="./posts/End-spurt-in-marathon/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://nienxiangtou.com/posts/End-spurt-in-marathon/image.webp" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
The end spurt in marathon running: A universal behaviour?
</h5>
<div class="listing-categories">
<div class="listing-category" onclick="window.quartoListingCategory('Sport science'); return false;">
Sport science
</div>
</div>
<div class="card-text listing-description">
This post examines the prevalence of the end spurt in marathon running based on data from Standard Chartered Singapore Marathon 2019.
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Nien Xiang Tou
</div>
<div class="listing-date">
Jul 29, 2020
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="5" data-categories="Football,Data visualisation" data-listing-date-sort="1593619200000" data-listing-file-modified-sort="1665545027184" data-listing-reading-time-sort="5.105">
<a href="./posts/Liverpool-success-lucky-or-worthy-winners/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://nienxiangtou.com/posts/Liverpool-success-lucky-or-worthy-winners/image.webp" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Liverpool’s success: Lucky or worthy winners?
</h5>
<div class="listing-categories">
<div class="listing-category" onclick="window.quartoListingCategory('Football'); return false;">
Football
</div>
<div class="listing-category" onclick="window.quartoListingCategory('Data visualisation'); return false;">
Data visualisation
</div>
</div>
<div class="card-text listing-description">
This post examines whether Liverpool’s title winning success is attributed to luck or genuine performance based on the expected goals metric.
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Nien Xiang Tou
</div>
<div class="listing-date">
Jul 2, 2020
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="6" data-categories="Data visualisation" data-listing-date-sort="1590768000000" data-listing-file-modified-sort="1664940485097" data-listing-reading-time-sort="3.94">
<a href="./posts/Spatial-visualisation-covid-clusters-sgp/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://nienxiangtou.com/posts/Spatial-visualisation-covid-clusters-sgp/image.webp" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Spatial visualisation with ggmap: Covid-19 clusters in Singapore
</h5>
<div class="listing-categories">
<div class="listing-category" onclick="window.quartoListingCategory('Data visualisation'); return false;">
Data visualisation
</div>
</div>
<div class="card-text listing-description">
This article documents the visualisation of Singapore’s Covid-19 clusters on the map using R programming
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Nien Xiang Tou
</div>
<div class="listing-date">
May 30, 2020
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="7" data-categories="Sport science" data-listing-date-sort="1589558400000" data-listing-file-modified-sort="1664936794055" data-listing-reading-time-sort="4.16">
<a href="./posts/Pace-variation-in-marathon-running/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://nienxiangtou.com/posts/Pace-variation-in-marathon-running/image.webp" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Pace variation in Marathon running: Analysing data from Standard Chartered Singapore Marathon 2019
</h5>
<div class="listing-categories">
<div class="listing-category" onclick="window.quartoListingCategory('Sport science'); return false;">
Sport science
</div>
</div>
<div class="card-text listing-description">
This post examines whether variation in marathon running pace differs among runners of different performance levels.
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Nien Xiang Tou
</div>
<div class="listing-date">
May 16, 2020
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="8" data-categories="Data science" data-listing-date-sort="1588262400000" data-listing-file-modified-sort="1665545318455" data-listing-reading-time-sort="6.59">
<a href="./posts/web-scraping-goodreads/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://nienxiangtou.com/posts/web-scraping-goodreads/image.webp" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Web Scraping Goodreads with BeautifulSoup: Popular runnning books
</h5>
<div class="listing-categories">
<div class="listing-category" onclick="window.quartoListingCategory('Data science'); return false;">
Data science
</div>
</div>
<div class="card-text listing-description">
This post documents the use of Python to scrape popular running books from Goodreads using the BeautifulSoup package.
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Nien Xiang Tou
</div>
<div class="listing-date">
May 1, 2020
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="9" data-categories="Sport science" data-listing-date-sort="1587744000000" data-listing-file-modified-sort="1664937249813" data-listing-reading-time-sort="2.025">
<a href="./posts/lactate-paradox/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://nienxiangtou.com/posts/lactate-paradox/image.webp" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Lactate Paradox
</h5>
<div class="listing-categories">
<div class="listing-category" onclick="window.quartoListingCategory('Sport science'); return false;">
Sport science
</div>
</div>
<div class="card-text listing-description">
This post writes about the phenomenon of reduced blood lactate concentration found with increasing altitude.
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Nien Xiang Tou
</div>
<div class="listing-date">
Apr 25, 2020
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="10" data-categories="Data visualisation" data-listing-date-sort="1584979200000" data-listing-file-modified-sort="1665545112926" data-listing-reading-time-sort="1.87">
<a href="./posts/Animated-data-viz-covid19/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://nienxiangtou.com/posts/Animated-data-viz-covid19/image.webp" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Animated Data Visualisation of the Covid-19 Pandemic using R
</h5>
<div class="listing-categories">
<div class="listing-category" onclick="window.quartoListingCategory('Data visualisation'); return false;">
Data visualisation
</div>
</div>
<div class="card-text listing-description">
This article visualises how the covid-19 pandemic has evolved in certain countries using animated line plots in R.
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Nien Xiang Tou
</div>
<div class="listing-date">
Mar 24, 2020
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="11" data-categories="Data science,Football" data-listing-date-sort="1582128000000" data-listing-file-modified-sort="1665545283600" data-listing-reading-time-sort="5.545">
<a href="./posts/web-scraping-and-data-visualising-with-R-EPL19/20-goal-stats/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://nienxiangtou.com/posts/web-scraping-and-data-visualising-with-R-EPL19/20-goal-stats/image.webp" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Web Scraping and Data Visualising with R: EPL 19/20 Goal Stats
</h5>
<div class="listing-categories">
<div class="listing-category" onclick="window.quartoListingCategory('Data science'); return false;">
Data science
</div>
<div class="listing-category" onclick="window.quartoListingCategory('Football'); return false;">
Football
</div>
</div>
<div class="card-text listing-description">
This article documents a walk-through on web scraping data on English Premier League teams from Wikipedia and visualising the data using R.
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Nien Xiang Tou
</div>
<div class="listing-date">
Feb 20, 2020
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="12" data-categories="Data science,Football" data-listing-date-sort="1581177600000" data-listing-file-modified-sort="1665545259278" data-listing-reading-time-sort="3.79">
<a href="./posts/Is-the-EPL-getting-more-competitive/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://nienxiangtou.com/posts/Is-the-EPL-getting-more-competitive/image.webp" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Is the English Premier League getting more competitive?
</h5>
<div class="listing-categories">
<div class="listing-category" onclick="window.quartoListingCategory('Data science'); return false;">
Data science
</div>
<div class="listing-category" onclick="window.quartoListingCategory('Football'); return false;">
Football
</div>
</div>
<div class="card-text listing-description">
This post examines and compares the competitiveness of different English Premier LEague seasons based on coefficient of variation metric.
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Nien Xiang Tou
</div>
<div class="listing-date">
Feb 9, 2020
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="13" data-categories="Data science,Football" data-listing-date-sort="1565193600000" data-listing-file-modified-sort="1664936985822" data-listing-reading-time-sort="5.43">
<a href="./posts/Can-possession-predict-wins-in-football/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://nienxiangtou.com/posts/Can-possession-predict-wins-in-football/image.webp" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Can possession predict wins in football?
</h5>
<div class="listing-categories">
<div class="listing-category" onclick="window.quartoListingCategory('Data science'); return false;">
Data science
</div>
<div class="listing-category" onclick="window.quartoListingCategory('Football'); return false;">
Football
</div>
</div>
<div class="card-text listing-description">
This post explores the use of logistic regression to examine whether football possession can predict wins in football with data from EPL 18/19.
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Nien Xiang Tou
</div>
<div class="listing-date">
Aug 8, 2019
</div>
</div>
</div>
</div>
</a>
</div>
<div class="g-col-1" data-index="14" data-categories="Sport science" data-listing-date-sort="1564761600000" data-listing-file-modified-sort="1664936904974" data-listing-reading-time-sort="3.565">
<a href="./posts/Your-perception-is-your-reality/index.html" class="quarto-grid-link">
<div class="quarto-grid-item card h-100 card-left">
<p class="card-img-top">
<img src="https://nienxiangtou.com/posts/Your-perception-is-your-reality/image.webp" class="thumbnail-image card-img" style="height: 150px;">
</p>
<div class="card-body post-contents">
<h5 class="no-anchor card-title listing-title">
Your perception is your reality
</h5>
<div class="listing-categories">
<div class="listing-category" onclick="window.quartoListingCategory('Sport science'); return false;">
Sport science
</div>
</div>
<div class="card-text listing-description">
This post highlights the importance of study perception in the sport science domain, especially in the context of exercise regulation
</div>
<div class="card-attribution card-text-small justify">
<div class="listing-author">
Nien Xiang Tou
</div>
<div class="listing-date">
Aug 3, 2019
</div>
</div>
</div>
</div>
</a>
</div>
</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div> ]]></description>
  <guid>https://nienxiangtou.com/blog.html</guid>
  <pubDate>Wed, 12 Oct 2022 03:31:22 GMT</pubDate>
</item>
<item>
  <title>Nien Xiang Tou, PhD</title>
  <link>https://nienxiangtou.com/about.html</link>
  <description><![CDATA[ 
<p>I am a Research Fellow at Geriatric Education and Research Institute, Singapore. My background is in sports science, and I previously attained my PhD from Nanyang Technological University, Singapore. My present research work focuses on exercise and physical activity to promote healthy ageing and extend the health span of older adults.</p>
<p>Data and numbers make me tick. This blog documents my personal projects and my learning journey in programming languages such as R and Python. I write about various topics including statistics, data science, data visualisation, coding and sport science.</p>
<p>All views expressed here are my own.</p>


 ]]></description>
  <guid>https://nienxiangtou.com/about.html</guid>
  <pubDate>Wed, 12 Oct 2022 03:31:22 GMT</pubDate>
  <media:content url="https://nienxiangtou.com/Profilephoto.jfif" medium="image" type="image/jpeg"/>
</item>
</channel>
</rss>
